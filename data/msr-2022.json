[
    {
        "title": "An Empirical Evaluation of GitHub Copilot\u2019s Code Suggestions",
        "topics": "Technical Papers",
        "abstract": "GitHub and OpenAI recently launched GitHub Copilot, an \u201cAI pair programmer\u201d that utilizes the power of Natural Language Processing, Static Analysis, Code Synthesis, and Artificial Intelligence. Given a natural language description of the target functionality, Copilot can generate corresponding code in several programming languages. In this paper, we perform an empirical study to understand the correctness and understandability of the Copilot\u2019s suggested code. We use 33 LeetCode questions to create queries for Copilot in four different programming languages. We evaluate the correctness of the corresponding 132 Copilot solutions by running LeetCode\u2019s provided tests, and evaluate understandability using SonarQube\u2019s cyclomatic complexity and cognitive complexity metrics. We find that Copilot\u2019s Java suggestions have the highest correctness score (57%) while JavaScript is lowest (27%). Overall, Copilot\u2019s suggestions have low complexity with no notable differences between the programming languages. We also find some potential Copilot shortcomings, such as generating code that can be further simplified and code that relies on undefined helper methods.",
        "authors": [
            {
                "name": "Nhan Nguyen",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Sarah Nadi",
                "institution": "University of Alberta",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "An Alternative Issue Tracking Dataset of Public Jira Repositories",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Organisations use issue tracking systems (ITSs) to track and document their projects\u2019 work in units called issues. This style of documentation encourages evolutionary refinement, as each issue can be independently improved, commented on, linked to other issues, and progressed through the organisational workflow. Commonly studied ITSs so far include GitHub, GitLab, and Bugzilla, while Jira, one of the most popular ITS in practice with a wealth of additional information, has yet to receive such attention. Unfortunately, diverse public Jira datasets are rare, likely due to the difficulty in finding and accessing these repositories. With this paper, we release a dataset of 16 public Jiras with 1822 projects, spanning 2.7 million issues with a combined total of 32 million changes, 9 million comments, and 1 million issue links. We believe this Jira dataset will lead to many fruitful research projects investigating issue evolution, issue linking, cross-project analysis, as well as cross-tool analysis when combined with existing well-studied ITS datasets.",
        "authors": [
            {
                "name": "Lloyd Montgomery",
                "institution": "Universit\u00e4t Hamburg",
                "country": "Germany"
            },
            {
                "name": "Clara Marie L\u00fcders",
                "institution": "University of Hamburg",
                "country": "Germany"
            },
            {
                "name": "Walid Maalej",
                "institution": "University of Hamburg",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "Refactoring Debt: Myth or Reality? An Exploratory Study on the Relationship Between Technical Debt and Refactoring",
        "topics": "Mining Challenge",
        "abstract": "To meet project timelines or budget constraints, developers intentionally deviate from writing optimal code to feasible code in what is known as incurring Technical Debt (TD). Furthermore, as part of planning their correction, developers document these deficiencies as comments in the code (i.e., self-admitted technical debt or SATD). As a means of improving source code quality, developers often apply a series of refactoring operations to their codebase. In this study, we explore developers repaying this debt through refactoring operations by examining occurrences of SATD removal in the code of 76 open-source Java systems. Our findings show that TD payment usually occurs with refactoring activities and developers refactor their code to remove TD for specific reasons. We envision our findings supporting vendors in providing tools to better support developers in the automatic repayment of technical debt.",
        "authors": [
            {
                "name": "Anthony Peruma",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Christian D. Newman",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Towards Using Gameplay Videos for Detecting Issues in Video Games",
        "topics": "Registered Reports",
        "abstract": "\\textit{Context.} The game industry is increasingly growing in recent years. Every day, millions of people play video games, not only as a hobby, but also for professional competitions (e.g., e-sports or speedrunning) or for making business by entertaining others (e.g., streamers). The latter daily produce a large amount of gameplay videos in which they also comment live what they experience. Since no software and, thus, no video game is perfect, streamers may encounter several problems (such as bugs, glitches, or performance issues). However, it is unlikely that they explicitly report such issues to developers. The identified problems may negatively impact the user\u2019s gaming experience and, in turn, can harm the reputation of the game and of the producer. \\textit{Objective.} We aim at proposing and empirically evaluating GELID, an approach for automatically extracting relevant information from gameplay videos by (i) identifying video segments in which streamers experienced anomalies; (ii) categorizing them based on their type and context in which appear (e.g., bugs or glitches appearing in a specific level or scene of the game); and (iii) clustering segments that regard the same specific issue. \\textit{Method.} We will build on top of existing approaches able to identify videos that are relevant for a specific video game. These represent the input of GELID that processes them to achieve the defined objectives. We will experiment GELID on several gameplay videos to understand the extent to which each of its steps is effective.",
        "authors": [
            {
                "name": "Emanuela Guglielmi",
                "institution": "University of Molise",
                "country": null
            },
            {
                "name": "Simone Scalabrino",
                "institution": "University of Molise",
                "country": null
            },
            {
                "name": "Gabriele Bavota",
                "institution": "Software Institute, USI Universit\u00e0 della Svizzera italiana",
                "country": "Switzerland"
            },
            {
                "name": "Rocco Oliveto",
                "institution": "University of Molise",
                "country": null
            }
        ]
    },
    {
        "title": "Operationalizing Threats to MSR Studies by Simulation-Based Testing",
        "topics": "Technical Papers",
        "abstract": "Quantitative studies on the border between Mining Software Repository (MSR) and Empirical Software Engineering (ESE) apply data analysis methods, like regression modeling, statistic tests or correlation analysis, to commits or pulls to better understand the software development process. Such studies assure the validity of the reported results by following a sound methodology. However, with increasing complexity, parts of the methodology can still go wrong. This may result in MSR/ESE studies with undetected threats to validity. In this paper, we propose to systematically protect against threats by operationalizing their treatment using simulations. A simulation substitutes observed and unobserved data, related to an MSR/ESE scenario, with synthetic data, carefully defined according to plausible assumptions on the scenario. Within a simulation, unobserved data becomes transparent, which is the key difference to a real study, necessary to detect threats to an analysis methodology. Running an analysis methodology on synthetic data may detect basic technical bugs and misinterpretations, but it also improves the trust in the methodology. The contribution of a simulation is to operationalize testing the impact of important assumptions. Assumptions still need to be rated for plausibility. We evaluate simulation-based testing by operationalizing undetected threats in the context of four published MSR/ESE studies. We recommend that future research uses such more systematic treatment of threats, as a contribution against the reproducibility crisis.",
        "authors": [
            {
                "name": "Johannes H\u00e4rtel",
                "institution": "University of Koblenz-Landau",
                "country": "Germany"
            },
            {
                "name": "Ralf Laemmel",
                "institution": "Facebook London",
                "country": null
            }
        ]
    },
    {
        "title": "Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems",
        "topics": "Technical Papers",
        "abstract": "Software projects use Issue Tracking Systems (ITS) like JIRA to track issues and organize the workflows around them. Issues are often inter-connected via different links such as the default JIRA link types Duplicate, Relate, Block, and Subtask. While previous research has focused on analyzing and predicting duplication links, this work aims at understanding the various other link types, their prevalence, and characteristics towards a more reliable link type prediction.",
        "authors": [
            {
                "name": "Clara Marie L\u00fcders",
                "institution": "University of Hamburg",
                "country": "Germany"
            },
            {
                "name": "Abir Bouraffa",
                "institution": "University of Hamburg",
                "country": "Germany"
            },
            {
                "name": "Walid Maalej",
                "institution": "University of Hamburg",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "The General Index of Software Engineering Papers",
        "topics": "Data and Tool Showcase Track",
        "abstract": "We introduce the General Index of Software Engineering Papers, a dataset of fulltext-indexed papers from the most prominent scientific venues in the field of Software Engineering. The dataset includes both complete bibliographic information and indexed n-grams (sequence of contiguous words after removal of stopwords and non-words, for a total of 577\u2019276\u2019382 unique n-grams in this release) with length 1 to 5 for 44\u2019581 papers retrieved from 34 venues over the 1971\u20132020 period. The dataset serves use cases in the field of meta-research, allowing to introspect the output of software engineering research even when access to papers or scholarly search engines is not possible (e.g., due to contractual reasons). The dataset also contributes to making such analyses reproducible and independently verifiable, as opposed to what happens when they are conducted using 3rd-party and non-open scholarly indexing services. The dataset is available as a portable Postgres database dump and released as open data.",
        "authors": [
            {
                "name": "Zeinab Abou Khalil",
                "institution": "Inria",
                "country": null
            },
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "Geographic Diversity in Public Code Contributions",
        "topics": "Technical Papers",
        "abstract": "We conduct an exploratory, large-scale, longitudinal study of 50 years of commits to publicly available version control system repositories, in order to characterize the geographic diversity of contributors to public code and its evolution over time. We analyze in total 2.2 billion commits collected by Software Heritage from 160 million projects and authored by 43 million authors during the 1971-2021 time period. We geolocate developers to 12 world regions derived from the United Nation geoscheme, using as signals email top-level domains, author names compared with names distributions around the world, and UTC offsets mined from commit metadata. We find evidence of the early dominance of North America in open source software, later joined by Europe. After that period, the geographic diversity in public code has been constantly increasing. We also identify relevant historical shifts related to the UNIX wars, the increase of coding literacy in Central and South Asia, and broader phenomena like colonialism and people movement across countries (immigration/emigration).",
        "authors": [
            {
                "name": "Davide Rossi",
                "institution": "University of Bologna",
                "country": null
            },
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "Challenges and Future Research Direction for Microtask Programming in Industry",
        "topics": "Industry Track",
        "abstract": "Microtask programming is a solution to promote distributed development such as remote work in industry. The key idea of microtask programming in distributed development is to reduce face-to-face communication across developers by splitting the development task of software into independent microtasks. Our research team reported that microtask programming has potential benefits such as the fluidity of project assignments in industrial companies. However, we suppose it still has challenges. We found three key challenges that lie ahead to employ microtask programming in industry by our interview: well-being, motivation, and responsibility. Our presentation will describe our interview, these challenges, and future research direction.",
        "authors": [
            {
                "name": "Masanari Kondo",
                "institution": "Kyushu University",
                "country": "Japan"
            },
            {
                "name": "Shinobu Saito",
                "institution": "NTT",
                "country": "Japan"
            },
            {
                "name": "IIMURA Yukako",
                "institution": "NTT",
                "country": "Japan"
            },
            {
                "name": "Eunjong Choi",
                "institution": "Kyoto Institute of Technology",
                "country": "Japan"
            },
            {
                "name": "Osamu Mizuno",
                "institution": "Kyoto Institute of Technology",
                "country": "Japan"
            },
            {
                "name": "Yasutaka Kamei",
                "institution": "Kyushu University",
                "country": "Japan"
            },
            {
                "name": "Naoyasu Ubayashi",
                "institution": "Kyushu University",
                "country": "Japan"
            }
        ]
    },
    {
        "title": "Tooling for Time- and Space-efficient git Repository Mining",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Software projects under version control grow with each commit, accumulating up to hundreds of thousands of commits per repository. Especially for such large projects, the traversal of a repository and data extraction for static source code analysis poses a trade-off between granularity and speed.",
        "authors": [
            {
                "name": "Fabian Heseding",
                "institution": "Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam",
                "country": null
            },
            {
                "name": "Willy Scheibel",
                "institution": "Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam",
                "country": null
            },
            {
                "name": "J\u00fcrgen D\u00f6llner",
                "institution": "Hasso Plattner Institute, Digital Engineering Faculty, University of Potsdam",
                "country": null
            }
        ]
    },
    {
        "title": "ManyTypes4TypeScript: A Comprehensive TypeScript Dataset for Sequence-Based Type Inference",
        "topics": "Data and Tool Showcase Track",
        "abstract": "In this paper, we present ManyTypes4TypeScript, a very large corpus for training and evaluating machine-learning models for sequence-based type inference in TypeScript. The dataset includes over 9 million type annotations, across 13,953 projects and 539,571 files. The dataset is approximately 10x larger than analogous type inference datasets for Python, and is the largest available for TypeScript. We also provide API access to the dataset, which can be integrated into any tokenizer and used with any state-of-the-art sequence-based model. Finally, we provide analysis and performance results for state-of-the-art code-specific models, for baselining. ManyTypes4TypeScript is available on Huggingface, Zenodo, and CodeXGLUE.",
        "authors": [
            {
                "name": "Kevin Jesse",
                "institution": "University of California, Davis",
                "country": "United States"
            },
            {
                "name": "Prem Devanbu",
                "institution": "Department of Computer Science, University of California, Davis",
                "country": "United States"
            }
        ]
    },
    {
        "title": "GitDelver Enterprise Dataset (GDED): An Industrial Closed-source Dataset for Socio-Technical Research",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Conducting socio-technical software engineering research on closed-source software is difficult as most organizations do not want to give access to their code repositories. Most experiments and publications therefore focus on open-source projects which only provides a partial view of software development communities. Yet, closing the gap between open and closed source software industries is essential to increase the validity and applicability of results stemming from socio-technical software engineering research. We contribute to this effort by sharing our work in a large company counting 4,800 employees. We mined 101 repositories and produced the GDED dataset containing socio-technical information about 106,216 commits, 470,940 file modifications and 3,471,556 method modifications from 164 developers during the last 13 years, using various programming languages. For that, we used GitDelver, an open-source tool we developed on top of Pydriller, and anonymized and scrambled the data to comply with legal and corporate requirements. Our dataset can be used for various purposes and provides information about code complexity, self-admitted technical debt, bug fixes, as well as temporal information. We also share our experience regarding the processing of sensitive data to help other organizations making datasets publicly available to the research community.",
        "authors": [
            {
                "name": "Nicolas Riquet",
                "institution": "University of Namur",
                "country": "Belgium"
            },
            {
                "name": "Xavier Devroey",
                "institution": "University of Namur",
                "country": "Belgium"
            },
            {
                "name": "Beno\u00eet Vanderose",
                "institution": "University of Namur",
                "country": "Belgium"
            }
        ]
    },
    {
        "title": "The Unexplored Treasure Trove of Phabricator Code Reviews",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there does not exist a readily accessible public dataset of Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla) and discusses the problems associated with the data retrieval process. We publish a dataset with details of 317,476 code reviews conducted via Phabricator. Our dataset is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a finer granular level than is possible on the other platforms. In addition, given that the projects we mined are accessible via the Conduit API, our dataset can be used as a foundation to fetch additional details and insights.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": null
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Toward Granular Automatic Unit Test Case Generation",
        "topics": "Registered Reports",
        "abstract": "Unit testing verifies the presence of faults in individual software components. Previous research has been targeting the automatic generation of unit tests through the adoption of random or search-based algorithms. Despite their effectiveness, these approaches do not implement any strategy that allows them to create unit tests in a structured manner: indeed, they aim at creating tests by optimizing metrics like code coverage without ensuring that the resulting tests follow good design principles. In order to structure the automatic test case generation process, we propose a two-step systematic approach to the generation of unit tests: we first force search-based algorithms to create tests that cover individual methods of the production code, hence implementing the so-called intra-method tests; then, we relax the constraints to enable the creation of intra-class tests that target the interactions among production code methods.",
        "authors": [
            {
                "name": "Fabiano Pecorelli",
                "institution": "Tampere University",
                "country": "Finland"
            },
            {
                "name": "Giovanni Grano",
                "institution": "LocalStack",
                "country": "Switzerland"
            },
            {
                "name": "Fabio Palomba",
                "institution": "University of Salerno",
                "country": "Italy"
            },
            {
                "name": "Harald C. Gall",
                "institution": "University of Zurich",
                "country": null
            },
            {
                "name": "Andrea De Lucia",
                "institution": "University of Salerno",
                "country": "Italy"
            }
        ]
    },
    {
        "title": "On the Violation of Honesty in Mobile Apps: Automated Detection and Categories",
        "topics": "Technical Papers",
        "abstract": "Human values such as integrity, privacy, curiosity, security, and honesty are guiding principles for what people consider important in life. Such human values may be violated by mobile software applications (apps), and the negative effects of such human value violations can be seen in various ways in society. In this work, we focus on the human value of honesty. We present a model to support the automatic identification of violations of the value of honesty from app reviews from an end-user perspective. Beyond the automatic detection of honesty violations by apps, we also aim to better understand different categories of honesty violations expressed by users in their app reviews. The result of our manual analysis of our honesty violations dataset shows that honesty violations can be characterised into ten categories: unfair cancellation and refund policies; false advertisements; delusive subscriptions; cheating systems; inaccurate information; unfair fees; no service; deletion of reviews; impersonation; and fraudulent-looking apps. Based on these results, we argue for a conscious effort in developing more honest software artefacts including mobile apps, and the promotion of honesty as a key value in software development practices. Furthermore, we discuss the role of app distribution platforms as enforcers of ethical systems supporting human values, and highlight some proposed next steps for human values in software engineering (SE) research.",
        "authors": [
            {
                "name": "Humphrey Obie",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Idowu Oselumhe Ilekura",
                "institution": "Data Science Nigeria",
                "country": "Nigeria"
            },
            {
                "name": "Hung Du",
                "institution": "Applied Artificial Intelligence Institute, Deakin University",
                "country": "Australia"
            },
            {
                "name": "Mojtaba Shahin",
                "institution": "RMIT University, Australia",
                "country": "Australia"
            },
            {
                "name": "John Grundy",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Li Li",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Jon Whittle",
                "institution": "CSIRO's Data61 and Monash University",
                "country": "Australia"
            },
            {
                "name": "Burak Turhan",
                "institution": "University of Oulu",
                "country": "Finland"
            }
        ]
    },
    {
        "title": "Exploring Apache Incubator Project Trajectories with APEX",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Open Source Software (OSS) is a major component of our digital infrastructure, yet more than 80% of such projects fail. Seeking less uncertainty, many OSS projects join established software communities, e.g., the Apache Software Foundation (ASF), with established rules and community support to guide projects toward sustainability. In their nascent stage, ASF projects are incubated in the ASF incubator (ASFI), which provides systematic mentorship toward long-term sustainability. Projects in ASFI eventually conclude their incubation by either graduating, if successful, or retiring, if not.",
        "authors": [
            {
                "name": "Anirudh Ramchandran",
                "institution": "University of California, Davis",
                "country": "United States"
            },
            {
                "name": "Likang Yin",
                "institution": "University of California, Davis",
                "country": "United States"
            },
            {
                "name": "Vladimir Filkov",
                "institution": "University of California at Davis",
                "country": "United States"
            }
        ]
    },
    {
        "title": "DISCO: A Dataset of Discord Chat Conversations for Software Engineering Research",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Today, software developers work on complex and fast-moving projects that often require instant assistance from other domain and subject matter experts. Chat servers such as Discord facilitate live communication and collaboration among developers all over the world. With numerous topics discussed in parallel, mining and analyzing the chat data of these platforms would offer researchers and tool makers opportunities to develop software tools and services such as automated virtual assistants, chatbots, chat summarization techniques, Q&A thesaurus, and more.",
        "authors": [
            {
                "name": "Keerthana Muthu Subash",
                "institution": "Carleton University",
                "country": "Canada"
            },
            {
                "name": "Lakshmi Prasanna Kumar",
                "institution": "Carleton University",
                "country": "Canada"
            },
            {
                "name": "Sri Lakshmi Vadlamani",
                "institution": "Carleton University",
                "country": "Canada"
            },
            {
                "name": "Preetha Chatterjee",
                "institution": "Drexel University",
                "country": "USA"
            },
            {
                "name": "Olga Baysal",
                "institution": "Carleton University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "The OCEAN mailing list data set: Network analysis spanning mailing lists and code repositories",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Communication surrounding the development of an open source project largely occurs outside the software repository itself. Historically, large communities often used a collection of mailing lists to discuss the different aspects of their projects. Multimodal tool use, with software development and communication happening on different channels, complicates the study of open source projects as a sociotechnical system. Here, we combine and standardize mailing lists of the Python community, resulting in 954,287 messages from 1995 to the present. We share all scraping and cleaning code to facilitate reproduction of this work, as well as smaller datasets for the Golang (122,721 messages), Angular (20,041 messages) and Node.js (12,514 messages) communities. To showcase the usefulness of these data, we focus on the CPython repository and merge the technical layer (which GitHub account works on what file and with whom) with the social layer (messages from unique email addresses) by identifying 33% of GitHub contributors in the mailing list data. We then explore correlations between the valence of social messaging and the structure of the collaboration network. We discuss how these data provide a laboratory to test theories from standard organizational science in large open source projects.",
        "authors": [
            {
                "name": "Melanie Warrick",
                "institution": "University of Vermont",
                "country": "United States"
            },
            {
                "name": "Samuel F. Rosenblatt",
                "institution": "University of Vermont",
                "country": "United States"
            },
            {
                "name": "Jean-Gabriel Young",
                "institution": "University of Vermont",
                "country": "United States"
            },
            {
                "name": "amanda casari",
                "institution": "Open Source Programs Office, Google",
                "country": "United States"
            },
            {
                "name": "Laurent H\u00e9bert-Dufresne",
                "institution": "University of Vermont",
                "country": "United States"
            },
            {
                "name": "James P. Bagrow",
                "institution": "University of Vermont",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Do Customized Android Frameworks Keep Pace with Android?",
        "topics": "Technical Papers",
        "abstract": "To satisfy varying customer needs, device vendors and OS providers often rely on the open-source nature of the Android OS and offer customized versions of the Android OS. When a new version of the Android OS is released, device vendors and OS providers need to merge the changes from the Android OS into their customizations to account for its bug fixes, security patches, and new features. Because developers of customized OSs might have made changes to code locations that were also modified by the developers of the Android OS, the merge task can be characterized by conflicts, which can be time-consuming and error-prone to resolve.",
        "authors": [
            {
                "name": "Pei Liu",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Mattia Fazzini",
                "institution": "University of Minnesota",
                "country": "United States"
            },
            {
                "name": "John Grundy",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Li Li",
                "institution": "Monash University",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "On the Naturalness of Fuzzer Generated Code",
        "topics": "Technical Papers",
        "abstract": "Compiler fuzzing tools such as Csmith have uncovered many bugs in compilers by randomly sampling programs from a generative model. The success of these tools is often attributed to their ability to generate unexpected corner case inputs that developers tend to overlook during manual testing. At the same time, their chaotic nature makes fuzzer-generated test cases notoriously hard to interpret, which has lead to the creation of input simplification tools such as C-Reduce (for C compiler bugs). In until now unrelated work, researchers have also shown that human-written software tends to be rather repetitive and predictable to language models. Studies show that developers deliberately write more predictable code, whereas code with bugs is relatively unpredictable. In this study, we ask the natural questions of whether this high predictability property of code also, and perhaps counter-intuitively,  applies to fuzzer-generated code. That is, we investigate whether fuzzer-generated compiler inputs are deemed unpredictable by a language model built on human-written code and surprisingly conclude that \\emph{it is not}. To the contrary, Csmith fuzzer-generated programs are \\emph{more} predictable on a per-token basis than human-written C programs. Furthermore, bug-triggering tended to be more predictable still than random inputs, and the C-Reduce minimization tool did not substantially increase this predictability. Rather, we find that bug-triggering inputs are unpredictable relative to \\emph{Csmith\u2019s own} generative model. This is encouraging; our results suggest promising research directions on incorporating predictability metrics in the fuzzing and reduction tools themselves.",
        "authors": [
            {
                "name": "Rajeswari Hita Kambhamettu",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "John Billos",
                "institution": "Wake Forest University",
                "country": "United States"
            },
            {
                "name": "Carolyn \"Tomi\" Oluwaseun-Apo",
                "institution": "Pennsylvania State University",
                "country": "United States"
            },
            {
                "name": "Benjamin Gafford",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Rohan Padhye",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Vincent J. Hellendoorn",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "CLIP meets GamePhysics: Towards bug identification in gameplay videos using zero-shot transfer learning",
        "topics": "Technical Papers",
        "abstract": "Gameplay videos contain rich information about how players interact with the game and how the game responds. Sharing gameplay videos on social media platforms, such as Reddit, has become a common practice for many players. Often, players will share gameplay videos that showcase video game bugs. Such gameplay videos are software artifacts that can be utilized for game testing, as they provide insight for bug analysis. Although large repositories of gameplay videos exist, parsing and mining them in an effective and structured fashion has still remained a big challenge. In this paper, we propose a search method that accepts any English text query as input to retrieve relevant videos from large repositories of gameplay videos. Our approach does not rely on any external information (such as video metadata); it works solely based on the content of the video. By leveraging the zero-shot transfer capabilities of the Contrastive Language-Image Pre-Training (CLIP) model, our approach does not require any data labeling or training. To evaluate our approach, we present the GamePhysics dataset consisting of 26,954 videos from 1,873 games, that were collected from the GamePhysics section on the Reddit website. Our approach shows promising results in our extensive analysis of simple queries, compound queries, and bug queries, indicating that our approach is useful for object and event detection in gameplay videos. An example application of our approach is as a gameplay video search engine to aid in reproducing video game bugs. A demo of our approach can be found at the following link:HTTP://165.232.141.160:50001.",
        "authors": [
            {
                "name": "Mohammad Reza Taesiri",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Finlay Macklon",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Cor-Paul Bezemer",
                "institution": "University of Alberta",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Improve Quality of Cloud Serverless Architectures through Software Repository Mining",
        "topics": "Industry Track",
        "abstract": "Public cloud services have truly come of age for enterprises worldwide, with global spend forecast to grow 47.2% in 2022, reaching $397.4 billion, up from $270 billion in 2020, according to Gartner research. According to another analyst, Verified Market Research, the global Serverless architecture market size was valued at USD 7.29 billion in 2020 and is projected to reach USD 36.84 billion by 2028, growing at a CAGR of 21.71% from 2021 to 2028. With the growing complexity of cloud applications, meeting the demand of going from prototype to production to planet-scale is challenging. Serverless architectures ensure pay-as-you-go and can be invoked and scaled individually. Serverless is a method for executing functions and running cloud compute services on an as-needed basis. Serverless is the most scalable and cost-effective method for cloud computing. Enterprises that are adopting serverless architectures, can achieve their speed-to-market and business functionality goals only with a rigorous focus on quality from the start of their cloud journey and keep it up throughout. The goal? To increase quality, reduce cost and improve time-to-market across the journey to cloud.",
        "authors": [
            {
                "name": "Mallika Fernandes",
                "institution": null,
                "country": null
            },
            {
                "name": "Rohit Patwardhan",
                "institution": null,
                "country": null
            }
        ]
    },
    {
        "title": "Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes",
        "topics": "Technical Papers",
        "abstract": "Learning and predicting the performance of a configurable software system helps to provide better quality assurance. One important engineering decision therein is how to encode the configuration into the model built. Despite the presence of different encoding schemes, there is still little understanding of which is better and under what circumstances, as the community often relies on some general beliefs that inform the decision in an ad-hoc manner. To bridge this gap, in this paper, we empirically compared the widely used encoding schemes for software performance learning, namely label, scaled label, and one-hot encoding. The study covers five systems, seven models, and three encoding schemes, leading to 105 cases of investigation. Our key findings reveal that: (1) conducting trial-and-error to find the best encoding scheme in a case by case manner can be rather expensive, requiring up to 400+ hours on some models and systems; (2) the one-hot encoding often leads to the most accurate results while the scaled label encoding is generally weak on accuracy over different models; (3) conversely, the scaled label encoding tends to result in the fastest training time across the models/systems while the one-hot encoding is the slowest; (4) for all models studied, label and scaled label encoding often lead to relatively less biased outcomes between accuracy and training time, but the paired model varies according to the system.",
        "authors": [
            {
                "name": "Jingzhi Gong",
                "institution": "Loughborough University",
                "country": "United Kingdom"
            },
            {
                "name": "Tao Chen",
                "institution": "Loughborough University",
                "country": "United Kingdom"
            }
        ]
    },
    {
        "title": "TSSB-3M: Mining single statement bugs at massive scale",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Single statement bugs are one of the most important ingredients in the evaluation of modern bug detection and automatic program repair methods. By affecting only a single statement, single statement bugs represent a type of bug often overlooked by developers, while still being small enough to be detected and fixed by automatic methods.",
        "authors": [
            {
                "name": "Cedric Richter",
                "institution": "Carl von Ossietzky Universit\u00e4t Oldenburg / University of Oldenburg",
                "country": "Germany"
            },
            {
                "name": "Heike Wehrheim",
                "institution": "Carl von Ossietzky Universit\u00e4t Oldenburg / University of Oldenburg",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "Challenges in Migrating Imperative Deep Learning Programs to Graph Execution: An Empirical Study",
        "topics": "Technical Papers",
        "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code that supports symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce DL code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. While hybrid approaches aim for the \u201cbest of both worlds,\u201d the challenges in applying them in the real world are largely unknown. We conduct a data-driven analysis of challenges\u2014and resultant bugs\u2014involved in writing reliable yet performant imperative DL code by studying 250 open-source projects, consisting of 19.7 MLOC, along with 470 and 446 manually examined code patches and bug reports, respectively. The results indicate that hybridization: (i) is prone to API misuse, (ii) can result in performance degradation\u2014the opposite of its intention, and (iii) has limited application due to execution mode incompatibility. We put forth several recommendations, best practices, and anti-patterns for effectively hybridizing imperative DL code, potentially benefiting DL practitioners, API designers, tool developers, and educators.",
        "authors": [
            {
                "name": "Tatiana Castro V\u00e9lez",
                "institution": "City University of New York (CUNY) Graduate Center",
                "country": "United States"
            },
            {
                "name": "Raffi Khatchadourian",
                "institution": "City University of New York (CUNY) Hunter College",
                "country": "United States"
            },
            {
                "name": "Mehdi Bagherzadeh",
                "institution": "Oakland University",
                "country": "United States"
            },
            {
                "name": "Anita Raja",
                "institution": "City University of New York (CUNY) Hunter College",
                "country": "United States"
            }
        ]
    },
    {
        "title": "A Large-Scale Comparison of Python Code in Jupyter Notebooks and Scripts",
        "topics": "Technical Papers",
        "abstract": "In recent years, Jupyter notebooks have grown in popularity in several domains of software engineering, such as data science, machine learning, and computer science education. Their popularity has to do with their rich features for presenting and visualizing data, however, recent studies show that notebooks also share a lot of drawbacks: high number of code clones, low reproducibility, etc.",
        "authors": [
            {
                "name": "Konstantin Grotov",
                "institution": "JetBrains Research, ITMO University",
                "country": "Russia"
            },
            {
                "name": "Sergey Titov",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Vladimir Sotnikov",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Yaroslav Golubev",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Timofey Bryksin",
                "institution": "JetBrains Research; HSE University",
                "country": "Russia"
            }
        ]
    },
    {
        "title": "Senatus: A Fast and Accurate Code-to-Code Recommendation Engine",
        "topics": "Technical Papers",
        "abstract": "Machine learning on source code (MLOnCode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with \\emph{Senatus}, a new code-to-code recommendation engine. At the core of Senatus is \\emph{De-Skew} LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus and find the recommendations to be of higher quality than competing baselines, while achieving faster search. For example on the CodeSearchNet dataset Senatus improves performance by 31.21% F1 and  147.9\\emph{x} faster query time compared to Facebook Aroma. Senatus also outperforms standard MinHash LSH by 29.2% F1 and 51.02\\emph{x} faster query time.",
        "authors": [
            {
                "name": "Fran Silavong",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Sean Moran",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Antonios Georgiadis",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Rohan Saphal",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Robert Otter",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            }
        ]
    },
    {
        "title": "An Empirical Study on Maintainable Method Size in Java",
        "topics": "Technical Papers",
        "abstract": "Code metrics have been widely used to estimate software maintenance effort. Metrics have generally been used to guide developer effort to reduce or avoid future maintenance burdens. Size is the simplest and most widely deployed metric. The size metric is pervasive because size correlates with many other common metrics (e.g., McCabe complexity, readability, etc.). Given the ease of computing a method\u2019s size, and the ubiquity of these metrics in industrial settings, it is surprising that no systematic study has been performed to provide developers with meaningful method size guidelines with respect to future maintenance effort. In this paper we examine the evolution of \u223c785K Java methods and show that developers should strive to keep their Java methods under 24 lines in length. Additionally, we show that decomposing larger methods to smaller methods also decreases overall maintenance efforts. Taken together, these findings provide empirical guidelines to help developers design their systems in a way that can reduce future maintenance.",
        "authors": [
            {
                "name": "Shaiful Chowdhury",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Gias Uddin",
                "institution": "University of Calgary",
                "country": "Canada"
            },
            {
                "name": "Reid Holmes",
                "institution": "University of British Columbia",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "CamBench - Cryptographic API Misuse Detection Tool Benchmark Suite",
        "topics": "Registered Reports",
        "abstract": "Context: Cryptographic APIs are often misused in real-world applications. Therefore, many cryptographic API misuse detection tools have been introduced. However, there exists no established reference benchmark for a fair and comprehensive comparison and evaluation of these tools. While there are benchmarks, they often only address a subset of the domain or were only used to evaluate a subset of existing misuse detection tools. Objective: To fairly compare cryptographic API misuse detection tools and to drive future development in this domain, we will devise such a benchmark. Openness and transparency in the generation process are key factors to fairly generate and establish the needed benchmark. Method:We propose an approach where we derive the benchmark generation methodology from the literature which consists of general best practices in benchmarking and domain-specific benchmark generation. A part of this methodology is transparency and openness of the generation process, which is achieved by pre-registering this work. Based on our methodology we design CamBench, a fair \u201cCryptographic API Misuse Detection Tool Benchmark Suite\u201d. We will implement the first version of CamBench limiting the domain to Java, the JCA, and static analyses. Finally, we will use CamBench to compare current misuse detection tools and compare CamBench to related benchmarks of its domain.",
        "authors": [
            {
                "name": "Michael Schlichtig",
                "institution": "Heinz Nixdorf Institute at Paderborn University",
                "country": "Germany"
            },
            {
                "name": "Anna-Katharina Wickert",
                "institution": "TU Darmstadt",
                "country": "Germany"
            },
            {
                "name": "Stefan Kr\u00fcger",
                "institution": "Independent Researcher",
                "country": "Germany"
            },
            {
                "name": "Eric Bodden",
                "institution": "University of Paderborn; Fraunhofer IEM",
                "country": "Germany"
            },
            {
                "name": "Mira Mezini",
                "institution": "TU Darmstadt",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "Multimodal Recommendation of Messenger Channels",
        "topics": "Technical Papers",
        "abstract": "Collaboration platforms, such as GitHub and Slack, are a vital instrument in the day-to-day routine of software engineering teams. The data stored in these platforms has a significant value for data-driven methods that assist with decision-making and help improve software quality. However, the distribution of this data across different platforms leads to the fact that combining it is a very time-consuming process. Most existing algorithms for socio-technical assistance, such as recommendation systems, are based only on data directly related to the purpose of the algorithms, often originating from a single system.",
        "authors": [
            {
                "name": "Ekaterina Koshchenko",
                "institution": "JetBrains Research",
                "country": "Netherlands"
            },
            {
                "name": "Egor Klimov",
                "institution": "JetBrains Research",
                "country": "Netherlands"
            },
            {
                "name": "Vladimir Kovalenko",
                "institution": "JetBrains Research",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Improved Business Outcomes from Cloud Applications \u2013 using Integrated Process and Runtime Product Data Mining",
        "topics": "Industry Track",
        "abstract": "Cloud computing promises to enhance business flexibility, efficiency, scalability, and reliability. According to a recent survey from O\u2019Reilly, cloud adoption is steadily rising across industries, with 90% of organizations using cloud computing. Not only is cloud adoption growing, but enterprises are approaching cloud migration aggressively. Often, it is incorrectly assumed that services rendered by cloud either as platform or infrastructure will itself deliver the business outcomes of improved availability, business performance, security, and efficiency provided the application delivers the functionality. This is far from true. Cloud applications must be optimally architected, tested and operated for realizing the intended business outcomes. The considerations, choices and decisions taken in each of these lifecycle phases impact technical performance and as a result business outcome. Architecture considerations include decisions on choice of cloud services to be employed, design principles to apply, configuration parameters to tune, etc. Testing considerations include simulation of load and fault conditions that closely mirror runtime conditions and mining behavior for anomalies and faults. Operations considerations include monitoring critical parameters, identifying imminent failures (a.k.a incidents), taking preventive decisions, detecting failures, and taking recovery decisions etc. The challenge for businesses is that the cloud application runtime behavior consequences of these decisions are not easily envisaged by architects, developers, testers, and operators leading to sub-optimal business outcomes, reliability, and security issues. In addition, the decisions taken by architects, testers and operators are often inconsistent and incompatible with each other further aggravating the problem. In this Industry Track Paper (single pager) we intend to present these challenges and call for industry-academic collaboration to explore mining and modeling approaches to address the challenges",
        "authors": [
            {
                "name": "Mahesh Venkataraman",
                "institution": "Accenture",
                "country": "India"
            },
            {
                "name": "Reuben George",
                "institution": "Accenture",
                "country": "India"
            },
            {
                "name": "Jeff Wilkinson",
                "institution": "Accenture",
                "country": "India"
            }
        ]
    },
    {
        "title": "Inspect4py: A Knowledge Extraction Framework for Python Code Repositories",
        "topics": "Data and Tool Showcase Track",
        "abstract": "This works presents inspect4py, a static code analysis framework designed to automatically extract the main features, metadata and documentation of Python code repositories. Given an input folder with code, inspect4py uses abstract syntax trees and state of the art tools to find all functions, classes, tests, documentation, call graphs, module dependencies and control flows within all code files in that repository. Using these findings, inspect4py infers different ways of invoking a software component. We have evaluated our framework on 95 annotated repositories, obtaining promising results for software type classification (over 95% F1-score). With inspect4py, we aim to ease the understandability and adoption of software repositories by other researchers and developers.",
        "authors": [
            {
                "name": "Rosa Filgueira",
                "institution": "St. Andrews University",
                "country": null
            },
            {
                "name": "Daniel Garijo",
                "institution": "Universidad Polit\u00e9cnica de Madrid",
                "country": null
            }
        ]
    },
    {
        "title": "Vul4J: A Dataset of Reproducible Java Vulnerabilities Geared Towards the Study of Program Repair Techniques",
        "topics": "Data and Tool Showcase Track",
        "abstract": "In this work we present Vul4J, a Java vulnerability dataset where each vulnerability is associated to a patch and, most importantly, to a Proof of Vulnerability (PoV) test case. We analyzed 1803 fix commits from 912 real-world vulnerabilities in theProject KBknowledge base to extract thereproduciblevulnerabilities, i.e., vulnerabilities that can be triggered by one or more PoV test cases. To this aim, we ran the test suite of the application in both, the vulnerable and secure versions, to identify the corresponding PoVs. Furthermore, if no PoV test case was spotted, then we wrote it ourselves. As a result, Vul4J includes 79 reproducible vulnerabilities from 51 open-source projects, spanning 25 different Common Weakness Enumeration (CWE) types. To the extent of our knowledge, this is the first dataset of its kind created for Java. Particularly, it targets the study of Automated Program Repair (APR) tools, where PoVs are often necessary in order to identify plausible patches. We made our dataset and related tools publically available on GitHub.",
        "authors": [
            {
                "name": "Quang-Cuong Bui",
                "institution": "Hamburg University of Technology",
                "country": "Germany"
            },
            {
                "name": "Riccardo Scandariato",
                "institution": "Hamburg University of Technology",
                "country": "Germany"
            },
            {
                "name": "Nicol\u00e1s E. D\u00edaz Ferreyra",
                "institution": "Hamburg University of Technology",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "A Culture of Productivity: Maximizing Productivity by Maximizing Wellbeing",
        "topics": "Industry Track",
        "abstract": "Happy developers are productive developers. Productivity Engineer Brian Houck will share a practitioner\u2019s perspective on how engineering teams across Microsoft are investing in employee wellbeing to make a measurable impact on developer productivity. Measuring developer productivity across multiple dimensions by using a mix of methods, Houck takes a human-centered approach to understanding and maximizing productivity and happiness in his organization. This talk will explore real-world examples of a human centered approach improving the productivity of development teams within Microsoft. How can developers balance their time between collaboration and focused individual work? What impact does social connectedness have on the onboarding of new software engineers? Can more days off actually result in more work getting done? Learn answers to these questions and more!",
        "authors": [
            {
                "name": "Brian Houck",
                "institution": "Microsoft Research",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Characterizing High-Quality Test Methods: A First Empirical Study",
        "topics": "Technical Papers",
        "abstract": "To assess the quality of a test suite, one can rely on mutation testing, which computes whether the overall test cases are adequately exercising the covered lines. However, this high level of granularity may overshadow the quality of individual test methods. Thus, we propose an empirical study of high-quality test methods by mutation testing. We analyze over 18K test methods from popular software projects and show empirical evidence that high-quality test methods: (1) are slightly smaller; (2) have fewer modifications over time; (3) are less affected by critical test smells. Lastly, we present practical implications for researchers and practitioners.",
        "authors": [
            {
                "name": "Victor Veloso",
                "institution": "UFMG",
                "country": "Brazil"
            },
            {
                "name": "Andre Hora",
                "institution": "UFMG",
                "country": "Brazil"
            }
        ]
    },
    {
        "title": "DaSEA \u2013 A Dataset for Software Ecosystem Analysis",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Software package managers facilitate reuse and rapid construc- tion of software systems. Since evermore software is distributed via package managers, researchers and practitioners require ex- plicit data of software dependency networks that are opaquely formed by dependency relations between software packages. To reason about increasingly complex software products and ecosys- tems, researchers and practitioners rely either on publicly available datasets like the seemingly unattended libraries.io [15] or they mine problem-specific data from software ecosystems repeatedly and non-transparently. Therefore, we present the DaSEA dataset, which contains metadata of software packages, their versions, and de- pendencies from multiple ecosystems (currently six programming languages and five operating system package managers). Alongside the dataset, we provide an extensible open-source tool under the same name that is used to create updated versions of the DaSEA dataset allowing studies of evolution of software ecosystems.",
        "authors": [
            {
                "name": "Petya Buchkova",
                "institution": "IT University of Copenhagen",
                "country": null
            },
            {
                "name": "Joakim Hey Hinnerskov",
                "institution": "IT University of Copenhagen",
                "country": null
            },
            {
                "name": "Kasper Olsen",
                "institution": "IT University of Copenhagen",
                "country": null
            },
            {
                "name": "Rolf-Helge Pfeiffer",
                "institution": "IT University of Copenhagen",
                "country": null
            }
        ]
    },
    {
        "title": "npm-filter: Automating the mining of dynamic information from npm packages",
        "topics": "Data and Tool Showcase Track",
        "abstract": "The static properties of code repositories, e.g., lines of code, dependents, dependencies, etc. can be readily scraped from code hosting platforms such as GitHub, and from package management systems such as npm for JavaScript; Although no less important, information related to the \\textit{dynamic} properties of programs, e.g., number of tests in a test suite that pass or fail, is less readily available. The ability to easily collect this dynamic information could be immensely useful to researchers conducting corpus analyses, as they could differentiate projects based on properties that can only be observed by running them.",
        "authors": [
            {
                "name": "Ellen Arteca",
                "institution": "Northeastern University",
                "country": "United States"
            },
            {
                "name": "Alexi Turcotte",
                "institution": "Northeastern University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Mining the Ethereum Blockchain Platform: Best Practices and Pitfalls",
        "topics": "Tutorials",
        "abstract": null,
        "authors": [
            {
                "name": "Gustavo A. Oliva",
                "institution": "Queen's University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Bias in MSR research",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Alexander Serebrenik",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "TriggerZoo: A Dataset of Android Applications Automatically Infected with Logic Bombs",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Many Android apps analyzers rely, among other techniques, on dynamic analysis to monitor their runtime behavior and detect potential security threats. However, malicious developers use subtle, though efficient, techniques to bypass dynamic analyzers. Logic bombs are examples of popular techniques where the malicious code is triggered only under specific circumstances, challenging comprehensive dynamic analyses. The research community has proposed various approaches and tools to detect logic bombs. Unfortunately, rigorous assessment and fair comparison of state-of-the-art techniques are impossible due to the lack of ground truth. In this paper, we contribute with TriggerZoo, a new dataset of 406 Android apps containing logic bombs and benign trigger-based behavior that we release only to the research community using authenticated API. These apps are real-world apps from Google Play that have been automatically infected by our tool AndroBomb. The injected pieces of code implementing the logic bombs cover a large pallet of realistic logic bomb types that we have manually characterized from a set of real logic bombs. Researchers can exploit this dataset as ground truth to assess their approaches and provide comparisons against other tools.",
        "authors": [
            {
                "name": "Jordan Samhi",
                "institution": "University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Tegawend\u00e9 F. Bissyand\u00e9",
                "institution": "SnT, University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Jacques Klein",
                "institution": "University of Luxembourg",
                "country": "Luxembourg"
            }
        ]
    },
    {
        "title": "AndroOBFS: Time-tagged Obfuscated Android Malware Dataset with Family Information",
        "topics": "Data and Tool Showcase Track",
        "abstract": "With the large-scale adaptation of Android OS and ever-increasing contributions in the Android application space, Android has become the number one target of malware writers. In recent years, a large number of automatic malware detection and classification systems have evolved to tackle the dynamic nature of malware growth using either static or dynamic analysis techniques. Performance of static malware detection methods degrade due to the obfuscation attacks. Although many benchmark datasets are available to measure the performance of malware detection and classification systems, only a single obfuscated malware dataset (PRAGuard) is available to showcase the efficacy of the existing malware detection systems against the obfuscation attacks. PRAGuard contains outdated samples till March 2013 and does not represent the latest application categories. Moreover, PRAGuard does not provide the family information for malware because of which PRAGuard can not be used to evaluate the efficacy of the malware family classification systems.",
        "authors": [
            {
                "name": "Saurabh Kumar",
                "institution": "Indian Institute of Technology Kanpur",
                "country": "India"
            },
            {
                "name": "Debadatta Mishra",
                "institution": null,
                "country": null
            },
            {
                "name": "Biswabandan Panda",
                "institution": "Indian Institute of Technology Bombay",
                "country": "India"
            },
            {
                "name": "Sandeep K. Shukla",
                "institution": "Indian Institute of Technology Kanpur",
                "country": null
            }
        ]
    },
    {
        "title": "The Next Generation of Software Developers",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Denae Ford",
                "institution": "Microsoft Research",
                "country": "United States"
            }
        ]
    },
    {
        "title": "SniP: An Efficient Stack Tracing Framework for Multi-threaded Programs",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Usage of the execution stack at run-time captures the dynamic state of programs and can be used to derive useful insights into the program behaviour. The stack usage information can be used to identify and debug performance and security aspects of applications. Binary run-time instrumentation techniques are well known to capture the memory access traces during program execution. Tracing the program in entirety and filtering out stack specific accesses is a commonly used technique for stack related analysis. However, applying vanilla tracing techniques (using tools like Intel Pin) for multi-threaded programs has challenges such as identifying the stack areas to perform efficient run-time tracing.",
        "authors": [
            {
                "name": "Arun KP",
                "institution": "Indian Institute of Technology Kanpur",
                "country": "India"
            },
            {
                "name": "Saurabh Kumar",
                "institution": "Indian Institute of Technology Kanpur",
                "country": "India"
            },
            {
                "name": "Debadatta Mishra",
                "institution": null,
                "country": null
            },
            {
                "name": "Biswabandan Panda",
                "institution": "Indian Institute of Technology Bombay",
                "country": "India"
            }
        ]
    },
    {
        "title": "WeakSATD: detecting weak self-admitted technical debt",
        "topics": "Technical Papers",
        "abstract": "Speeding up development may produce technical debt, i.e., not-quite-right code for which the effort to make it right increases with time as a sort of interest. Developers may be aware of the debt as they  admit it in their code comments.   Literature reports that such a self-admitted technical debt survives for a long time in a program, but it is not yet clear its impact on the quality of the code on the long term. We argue that self-admitted technical debt contains a number of different weaknesses that may affect the security of a program. Therefore, the longer a debt is not paid back the higher is the risk that the weaknesses can be exploited. To discuss our claim and rise the developers\u2019 awareness on the vulnerability of the self-admitted technical debt that are not paid back, we explore the self-admitted technical debt in the Chromium C-code to detect any known weaknesses. In this preliminary study, we first mine the Common Weakness Enumeration repository to define  heuristics for the automatic detection and fix of weak code. Then, we parse the C-code to find self-admitted technical debt and the code block it refers to.  Finally, we use the heuristics to find weak code snippets associated to self-admitted technical debt and recommend their potential mitigation to developers. Such knowledge can be used to prioritize self-admitted technical debt for repair. A prototype has been developed and applied to the Chromium code. Initial findings report that  55% of self-admitted technical debt code contains weak code of 14 different types.",
        "authors": [
            {
                "name": "Barbara Russo",
                "institution": "Free University of Bolzano",
                "country": "Italy"
            },
            {
                "name": "Matteo Camilli",
                "institution": "Free University of Bozen-Bolzano",
                "country": "Italy"
            },
            {
                "name": "Moritz Mock",
                "institution": "Free University of Bolzano",
                "country": "Italy"
            }
        ]
    },
    {
        "title": "Lupa: A Platform for Large Scale Analysis of The Progamming Language Usage",
        "topics": "Data and Tool Showcase Track",
        "abstract": "In this paper, we present Lupa - a framework for large-scale analysis of the programming language usage. Lupa is a command line tool that uses the power of the IntelliJ Platform under the hood, which gives it access to powerful static analysis tools used in modern IDEs. The tool supports custom analyzers that process the rich concrete syntax tree of the code and can calculate its various features: the presence of entities, their dependencies, definition-usage chains, etc. Currently, Lupa supports analyzing Python and Kotlin, but can be extended to other languages supported by IntelliJ-based IDEs. We explain the internals of the tool, show how it can be extended and customized, and describe an example analysis that we carried out with its help: analyzing the syntax of ranges in Kotlin.",
        "authors": [
            {
                "name": "Anna Vlasova",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Maria Tigina",
                "institution": "JetBrains Research, ITMO University",
                "country": "Russia"
            },
            {
                "name": "Ilya Vlasov",
                "institution": "Saint Petersburg State University",
                "country": "Russia"
            },
            {
                "name": "Anastasiia Birillo",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Yaroslav Golubev",
                "institution": "JetBrains Research",
                "country": "Russia"
            },
            {
                "name": "Timofey Bryksin",
                "institution": "JetBrains Research; HSE University",
                "country": "Russia"
            }
        ]
    },
    {
        "title": "BotHunter: An Approach to Detect Software Bots in GitHub",
        "topics": "Technical Papers",
        "abstract": "Bots have become popular in software projects as they play critical roles, from running tests to fixing bugs/vulnerabilities. However, the large number of software bots adds extra effort on practitioners and researchers to distinguish human accounts from bot accounts to avoid bias in data-driven studies. Researchers developed several approaches to identify bots at specific activity levels (issue/pull request or commit), considering a single repository, and disregarding features that were shown to be effective in other domains. To address this gap, we propose using a machine learning based approach to identify the bot accounts regardless of their activity level. We extracted 19 features related to the account\u2019s profile information, activities, and comment similarity. Then, we evaluated the performance of five machine learning classifiers using a dataset that has more than 5,000 GitHub accounts. Our results show that the Random Forest classifier performs the best with an F1-score of 92.4% and AUC of 98.7%. Furthermore, the account profile information (e.g., account login) are the most important features to identify the account type. Finally, we compare the performance of the Random Forest classifier to the state-of-the-art approaches, and our results show that our Random Forest model outperforms the state-of-the-art techniques in identifying the account types regardless of their activity level.",
        "authors": [
            {
                "name": "Ahmad Abdellatif",
                "institution": "Concordia University",
                "country": "Canada"
            },
            {
                "name": "Mairieli Wessel",
                "institution": "Delft University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Igor Steinmacher",
                "institution": "Northern Arizona University",
                "country": "Brazil"
            },
            {
                "name": "Marco Gerosa",
                "institution": "Northern Arizona University, USA",
                "country": "United States"
            },
            {
                "name": "Emad Shihab",
                "institution": "Concordia University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "The Unsolvable Problem or the Unheard Answer? A Dataset of 24,669 Open-Source Software Conference Talks",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Talks at practitioner-focused open-source software conferences are a valuable source of information for software engineering researchers. They provide a pulse of the community and are valuable source material for grey literature analysis. We curated a dataset of 24,669 talks from 87 open-source conferences between 2010 and 2021. We stored all relevant metadata from these conferences and provide scripts to collect the transcripts. We believe this data is useful for answering many kinds of questions, such as: What are the important/highly discussed topics within practitioner communities? How do practitioners interact? And how do they present themselves to the public? We demonstrate the usefulness of this data by reporting our findings from two small studies: a topic model analysis providing an overview of open-source community dynamics since 2011 and a qualitative analysis of a smaller community-oriented sample within our dataset to gain a better understanding of why contributors leave open-source.",
        "authors": [
            {
                "name": "Kimberly Truong",
                "institution": "Oregon State University",
                "country": "United States"
            },
            {
                "name": "Courtney Miller",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Bogdan Vasilescu",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Christian K\u00e4stner",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Dataset: Dependency Networks of Open Source Libraries Available Through CocoaPods, Carthage and Swift PM",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Third party libraries are used to integrate existing solutions for common problems and help speed up development. The use of third party libraries, however, can carry risks, for example through vulnerabilities in these libraries. Studying the dependency networks of package managers lets us better understand and mitigate these risks. So far, the dependency networks of the three most important package managers of the Apple ecosystem, CocoaPods, Carthage and Swift PM, have not been studied. We analysed the dependencies for all publicly available open source libraries up to December 2021 and compiled a dataset containing the dependency networks of all three package managers. The dependency networks can be used to analyse how vulnerabilities are propagated through transitive dependencies. In order to ease the tracing of vulnerable libraries we also queried the NVD database and included publicly reported vulnerabilities for these libraries in the dataset.",
        "authors": [
            {
                "name": "Kristiina Rahkema",
                "institution": "University of Tartu",
                "country": "Estonia"
            },
            {
                "name": "Dietmar Pfahl",
                "institution": "University of Tartu",
                "country": "Estonia"
            }
        ]
    },
    {
        "title": "How heated is it? Understanding GitHub locked issues",
        "topics": "Technical Papers",
        "abstract": "Although issues are created to discuss and solve technical problems, conversations can get heated, with discussants getting angry and/or excited for a variety of reasons, such as poor suggestions or even, the violation of community conventions. To prevent and mitigate discussions from getting heated, communities like GitHub have introduced the ability to lock issue discussions that violate the code of conduct or other community guidelines. Despite some early research on locked issues, there is a lack of understanding of how communities use this feature and of potential threats to validity for researchers relying on a dataset of locked issues as an oracle for heated discussions. To address this gap, we (i) quantitatively analyzed 79 GitHub projects that have at least one issue locked as too heated, and (ii) qualitatively analyzed all issues locked as too heated of the 79 projects, a total of 205 issues and 5,511 comments. We found that projects have different behaviors when locking issues: 14 projects locked more than 90% of their closed issues, 54 locked less than 10% of their closed issues, and 11 locked between 54% and 88% of their closed issues. Additionally, locked issues tend to have more comments and more participants compared to non-locked issues. For the 205 issues locked as too heated, we found that one-third did not contain any uncivil discourse, and only 8.82% of the analyzed comments are actually uncivil. Finally, we found that the locking justifications provided by maintainers do not always match the label used to lock the issue. Based on our results, we identify three pitfalls to avoid when using the GitHub locked issues data.",
        "authors": [
            {
                "name": "Isabella Ferreira",
                "institution": "Polytechnique Montr\u00e9al",
                "country": "Canada"
            },
            {
                "name": "Bram Adams",
                "institution": "Queen's University, Kingston, Ontario",
                "country": "Canada"
            },
            {
                "name": "Jinghui Cheng",
                "institution": "Polytechnique Montreal",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "It's all in your network: How mining developer collaboration allowed us to peer into complex socio-technical aspects of software development",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Daniela Damian",
                "institution": "University of Victoria",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "An Empirical Study on the Survival Rate of GitHub Projects",
        "topics": "Technical Papers",
        "abstract": "The number of Open Source projects hosted in social coding platforms such as GitHub is constantly growing. However, many of these projects are not regularly maintained and some are even abandoned shortly after they were created. In this paper we analyze early project development dynamics in software projects hosted on GitHub, including their survival rate. To this aim, we collected all 1,127 GitHub repositories from four different ecosystems (i.e., NPM packages, R packages, WordPress plugins and Laravel packages) created in 2016. We stored their activity in a time series database and analyzed their activity evolution along their lifespan, from 2016 to now. Our results reveal that the prototypical development process consists of intensive coding-driven active periods followed by long periods of inactivity. More importantly, we have found that a significant number of projects die in the first year of existence with the survival rate decreasing year after year. In fact, the probability of surviving longer than five years is less than 50% though some types of projects have better chances of survival.",
        "authors": [
            {
                "name": "Adem Ait-Fonolla",
                "institution": "IN3 - UOC",
                "country": "Spain"
            },
            {
                "name": "Javier Luis C\u00e1novas Izquierdo",
                "institution": "IN3 - UOC",
                "country": "Spain"
            },
            {
                "name": "Jordi Cabot",
                "institution": "Open University of Catalonia, Spain",
                "country": "Spain"
            }
        ]
    },
    {
        "title": "Is Refactoring Always a Good Egg? Exploring the Interconnection Between Bugs and Refactorings",
        "topics": "Mining Challenge",
        "abstract": "Bug fixing and code refactoring are two distinct maintenance actions with different goals. While bug fixing is a corrective change that eliminates a defect from the program, refactoring targets improving the internal quality (i.e., maintainability) of a software system without changing its functionality. Best practices and common intuition suggest that these code actions should not be mixed in a single code change. Furthermore, as refactoring aims for improving quality without functional changes, we would expect that refactoring code changes will not be sources of bugs. Nonetheless, empirical studies show that none of the above hypotheses are necessarily true in practice. In this paper, we empirically investigate the interconnection between bug-related and refactoring code changes using the SmartSHARK dataset. Our goal is to explore how often bug fixes and refactorings co-occur in a single commit (tangled changes) and whether refactoring changes themselves might induce bugs into the system. We found that it is not uncommon to have tangled commits of bug fixes and refactorings; 21% of bug-fixing commits include at least one type of refactoring on average. What is even more shocking is that 54% of bug-inducing commits also contain code refactoring changes. For instance, 10% (652 occurrences) of the Change Variable Type refactorings in the dataset appear in bug-inducing commits that make up 7.9% of the total inducing commits.",
        "authors": [
            {
                "name": "Amirreza Bagheri",
                "institution": "University of Szeged",
                "country": "Hungary"
            },
            {
                "name": "Peter Hegedus",
                "institution": "University of Szeged",
                "country": "Hungary"
            }
        ]
    },
    {
        "title": "Complex Python Features in the Wild",
        "topics": "Technical Papers",
        "abstract": "While Python is increasingly popular, program analysis tooling for Python is lagging. This is due, in part, to complex features of the Python language. In addition to the ``usual suspects'', reflection and dynamic execution, the Python language introduces other complex features with difficult to understand and model semantics, e.g., context managers, decorators, and generators, among others. This paper explores how often and in what ways developers use certain complex features. We address three research questions: (i)~How often do developers use certain complex Python features? (ii)~In what ways to developers use these features? (iii)~Does use of complex features increase or decrease over time?",
        "authors": [
            {
                "name": "Yi Yang",
                "institution": "Rensselaer Polytechnic Institute",
                "country": "United States"
            },
            {
                "name": "Ana Milanova",
                "institution": "Rensselaer Polytechnic Institute",
                "country": "United States"
            },
            {
                "name": "Martin Hirzel",
                "institution": "IBM Research",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Methods2Test: A dataset of focal methods mapped to test cases",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Unit testing is an essential part of the software development process, which helps to identify issues with source code in early stages of development and prevent regressions. Machine learning has emerged as viable approach to help software developers generate automated unit tests. However, generating reliable unit test cases that are semantically correct and capable of catching software bugs or unintended behavior via machine learning requires large, metadata-rich, datasets. In this paper we present Methods2Test: a large, supervised dataset of test cases mapped to corresponding methods under test (i.e., focal methods). This dataset contains 780,944 pairs of JUnit tests and focal methods, extracted from a total of 91,385 Java open source projects hosted on GitHub with licenses permitting re-distribution. The main challenge behind the creation of the Methods2Test was to establish a reliable mapping between a test case and the relevant focal method. To this aim, we designed a set of heuristics, based on developers\u2019 best practices in software testing, which identify the likely focal method for a given test case. To facilitate further analysis, we store a rich set of metadata for each method-test pair in JSON-formatted files. Additionally, we extract textual corpus from the dataset at different context levels, which we provide both in raw and tokenized forms, in order to enable researchers to train and evaluate machine learning models for Automated Test Generation. Methods2Test is publicly available at:https://github.com/microsoft/methods2test",
        "authors": [
            {
                "name": "Michele Tufano",
                "institution": "Microsoft",
                "country": null
            },
            {
                "name": "Shao Kun Deng",
                "institution": "Microsoft Corporation",
                "country": "United States"
            },
            {
                "name": "Neel Sundaresan",
                "institution": "Microsoft Corporation",
                "country": null
            },
            {
                "name": "Alexey Svyatkovskiy",
                "institution": null,
                "country": null
            }
        ]
    },
    {
        "title": "LibDB: An Effective and Efficient Framework for Detecting Third-Party Libraries in Binaries",
        "topics": "Technical Papers",
        "abstract": "Third-party libraries (TPLs) are reused frequently in software applications for reducing development cost. However, they could introduce security risks as well. Many TPL detection methods have been proposed to detect TPL reuse in Android bytecode or in source code. This paper focuses on detecting TPL reuse in binary code, which is a more challenging task. For a detection target in binary form, libraries may be compiled and linked to separate dynamic-link files or built into a fused binary that contains multiple libraries and project-specific code. This could result in fewer available code features and lower the effectiveness of feature engineering. In this paper, we propose a binary TPL reuse detection framework, LibDB, which can effectively and efficiently detect imported TPLs even in stripped and fused binaries. In addition to the basic and coarse-grained features(string literals and exported function names), LibDB utilizes function contents as a new type of feature. It embeds all functions in a binary file to low-dimensional representations with a trained neural network. It further adopts a function call graph-based comparison method to improve the accuracy of the detection. LibDB is able to support version identification of TPLs contained in the detection target, which is not considered by existing detection methods. To evaluate the performance of LibDB, we construct three datasets for binary-based TPL reuse detection. Our experimental results show that LibDB is more accurate and efficient than state-of-the-art tools on the binary TPL detection task and the version identification task. Our datasets and source code used in this work are anonymously available athttps://anonymous.4open.science/r/LibDB.",
        "authors": [
            {
                "name": "Wei Tang",
                "institution": "Tsinghua University",
                "country": "China"
            },
            {
                "name": "Yanlin Wang",
                "institution": "Microsoft Research",
                "country": "China"
            },
            {
                "name": "Hongyu Zhang",
                "institution": "University of Newcastle",
                "country": "Australia"
            },
            {
                "name": "Shi Han",
                "institution": "Microsoft Research",
                "country": "China"
            },
            {
                "name": "Ping Luo",
                "institution": "Tsinghua University",
                "country": "China"
            },
            {
                "name": "Dongmei Zhang",
                "institution": "Microsoft Research",
                "country": "China"
            }
        ]
    },
    {
        "title": "Noisy Label Learning for Security Defects",
        "topics": "Technical Papers",
        "abstract": "Data-driven software engineering processes, such as vulnerability prediction heavily rely on the quality of the data used. In this paper, we observe that noise-free security defect datasets are infeasible to be obtained in practice. Despite the vulnerable class, the non-vulnerable modules are difficult to be verified and determined as truly exploit free given the limited manual efforts available. It results in uncertainty, introducing labeling noise in the datasets and affecting conclusion validity. To address this issue, we propose novel learning methods that are robust to label impurities and can leverage the most from limited label data; noisy label learning. We investigate various noisy label learning methods applied to software vulnerability prediction. Specifically, we propose a two-stage learning method based on noise cleaning to identify and remediate the noisy samples, which improves AUC and recall of baselines by up to 8.9% and 23.4%, respectively. Moreover, we discuss several hurdles in terms of achieving a performance upper bound with semi-omniscient knowledge of the label noise. Overall, the experimental results show that learning from noisy labels can be effective for data-driven software and security analytics.",
        "authors": [
            {
                "name": "Roland Croft",
                "institution": "The University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Muhammad Ali Babar",
                "institution": "University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Huaming Chen",
                "institution": "The University of Adelaide",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "Is Surprisal in Issue Trackers Actionable?",
        "topics": "Registered Reports",
        "abstract": "Background.From information theory, surprisal is a measurement of how unexpected a particular event is. Statistical language models provide a probabilistic approximation of natural languages, and because surprisal is constructed with the probability of an event occuring, it is therefore possible to determine the surprisal associated with English sentences. The issues and pull requests of software repository issue trackers provide insight into the development process and likely contain the surprising events of this process.",
        "authors": [
            {
                "name": "James Caddy",
                "institution": "University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Markus Wagner",
                "institution": "University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Christoph Treude",
                "institution": "University of Melbourne",
                "country": "Australia"
            },
            {
                "name": "Earl T. Barr",
                "institution": "University College London",
                "country": "UK"
            },
            {
                "name": "Miltiadis Allamanis",
                "institution": "Microsoft Research",
                "country": null
            }
        ]
    },
    {
        "title": "On the Co-Occurrence of Refactoring of Test and Source Code",
        "topics": "Mining Challenge",
        "abstract": "Refactoring is a widespread practice that aims to help improve the quality of a software system without altering its external behaviour. In practice, developers can perform refactoring operations on test and source code. However, while prior work shows that refactoring source code brings many benefits, a limited number of studies empirically investigate refactoring of test code and whether it is co-occurred with source code. To examine those co-occurring refactorings, we conducted an empirical study of 60,465 commits spanning 77 open-source Java projects.",
        "authors": [
            {
                "name": "Nicholas Nagy",
                "institution": "Concordia University",
                "country": null
            },
            {
                "name": "Rabe Abdalkareem",
                "institution": "Carleton University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "On the Use of Fine-grained Vulnerable Code Statements for Software Vulnerability Assessment Models",
        "topics": "Technical Papers",
        "abstract": "Many studies have developed Machine Learning (ML) approaches to detect Software Vulnerabilities (SVs) in functions and fine-grained code statements that cause such SVs. However, there is little work on leveraging such detection outputs for data-driven SV assessment to give information about exploitability, impact, and severity of SVs. The information is important to understand SVs and prioritize their fixing. Using large-scale data from 1,782 functions of 429 SVs in 200 real-world projects, we investigate ML models for automating function-level SV assessment tasks, i.e., predicting seven Common Vulnerability Scoring System (CVSS) metrics. We particularly study the value and use of vulnerable statements as inputs for developing the assessment models because SVs in functions are originated in these statements. We show that vulnerable statements are 5.8 times smaller in size, yet exhibit 7.5-114.5% stronger assessment performance (Matthews Correlation Coefficient (MCC)) than non-vulnerable statements. Incorporating context of vulnerable statements further increases the performance by up to 8.9% (0.64 MCC and 0.75 F1-Score). Overall, we provide the initial yet promising ML-based baselines for function-level SV assessment, paving the way for further research in this direction.",
        "authors": [
            {
                "name": "Triet Le Huynh Minh",
                "institution": "The University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Muhammad Ali Babar",
                "institution": "University of Adelaide",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "FixJS: A Dataset of Bug-fixing JavaScript Commits",
        "topics": "Data and Tool Showcase Track",
        "abstract": "The field of Automated Program Repair (APR) has received increasing attention in recent years both from the academic world and from leading IT companies. It\u2019s main goal is to repair software bugs automatically, thus reducing the cost of development and maintenance significantly. Recent works use state-of-the-art deep learning models to predict correct patches, for these teaching on a large amount of data is inevitable almost in every scenarios. Despite this, readily accessible data on the field is very scarce. To contribute to related research, we present FixJS, a dataset containing bug-fixing information of ~ 2 million commits. The commits were gathered from GitHub and processed locally to have both the buggy (before bug fixing commit) and fixed (after fix) version of the same program. We focused on JavaScript functions, as it is one of the most popular programming language globally and functions are first class objects there. The data includes more than 300.000 samples of such functions, including commit information, before/after states and 3 source code representations.",
        "authors": [
            {
                "name": "Viktor Csuvik",
                "institution": "Department of Software Engineering, MTA-SZTE Research Group on Artificial Intelligence, University of Szeged",
                "country": "Hungary"
            },
            {
                "name": "L\u00e1szl\u00f3 Vid\u00e1cs",
                "institution": "University of Szeged",
                "country": "Hungary"
            }
        ]
    },
    {
        "title": "Mining Software Repositories in the age of AI",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Foutse Khomh",
                "institution": "Polytechnique Montre\u0301al",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "The Unexplored Treasure Trove of Phabricator Code Reviews",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there does not exist a readily accessible public dataset of Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla) and discusses the problems associated with the data retrieval process. We publish a dataset with details of 317,476 code reviews conducted via Phabricator. Our dataset is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a finer granular level than is possible on the other platforms. In addition, given that the projects we mined are accessible via the Conduit API, our dataset can be used as a foundation to fetch additional details and insights.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": "United States"
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "FaST: A linear time stack trace alignment heuristic for crash report deduplication",
        "topics": "Technical Papers",
        "abstract": "In software projects, applications are often monitored by systems that automatically identify crashes, collect their information into reports, and submit them to developers. Especially in popular applications, such systems tend to generate a large number of crash reports in which a significant portion of them are duplicate. Due to this high submission volume, in practice, the crash report deduplication is supported by devising automatic systems whose efficiency is a critical constraint. In this paper, we focus on improving deduplication system throughput by speeding up the stack trace comparison. In contrast to the state-of-the-art techniques, we propose FaST, a novel sequence alignment method that computes the similarity score between two stack traces in linear time. Our method independently aligns identical frames in two stack traces by means of a simple alignment heuristic. We evaluate FaST and five competing methods on four datasets from open-source projects using ranking and binary metrics. Despite its simplicity, FaST consistently achieves state-of-the-art performance regarding all metrics considered. Moreover, our experiments confirm that FaST is substantially more efficient than methods based on optimal sequence alignment.",
        "authors": [
            {
                "name": "Irving Muller Rodrigues",
                "institution": "Polytechnique Montreal",
                "country": "Canada"
            },
            {
                "name": "Daniel Aloise",
                "institution": "Polytechnique Montreal",
                "country": null
            },
            {
                "name": "Eraldo Rezende Fernandes",
                "institution": "Leuphana University of L\u00fcneburg",
                "country": null
            }
        ]
    },
    {
        "title": "Methods for Stabilizing Models across Large Samples of Projects(with case studies on Predicting Defect and Project Health)",
        "topics": "Technical Papers",
        "abstract": "Despite decades of research,   SE   lacks widely accepted models (that offer precise quantitative stable predictions) about what factors most influence software quality. This paper provides a promising result showing such stable models can be generated using a new transfer learning framework called \u201cSTABILIZER\u201d. Given a tree of recursively clustered projects (using project meta-data), STABILIZER promotes a model upwards if it performs best in the lower clusters (stopping when the promoted model performs worse than the models seen at a lower level).",
        "authors": [
            {
                "name": "Suvodeep Majumder",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tianpei Xia",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Rahul Krishna",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tim Menzies",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Constructing Dataset of Functionally Equivalent Java Methods Using Automated Test Generation Techniques",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Since programming languages offer a wide variety of grammers, desired functions can be implemented in a variety of ways.   We consider that there is a large amount of source code that has different implementations of the same functions, and that those can be compiled into a dataset that can be used for various research in software engineering.   In this study, we construct a dataset of Java methods with functionally equivalent functions from about 36 million lines of source code. The constructed dataset is available athttps://zenodo.org/record/5896268.",
        "authors": [
            {
                "name": "Yoshiki Higo",
                "institution": "Osaka University",
                "country": "Japan"
            },
            {
                "name": "Shinsuke Matsumoto",
                "institution": "Osaka University",
                "country": "Japan"
            },
            {
                "name": "Shinji Kusumoto",
                "institution": "Osaka University",
                "country": "Japan"
            },
            {
                "name": "Kazuya Yasuda",
                "institution": "Hitachi, Ltd.",
                "country": "Japan"
            }
        ]
    },
    {
        "title": "Mining Code Review Data to Understand Waiting Times Between Acceptance and Merging: An Empirical Analysis",
        "topics": "Technical Papers",
        "abstract": "Increasing code velocity (or the speed with which code changes are reviewed and merged) is integral to speeding up development and contributes to the work satisfaction of engineers. While factors affecting code change acceptance have been investigated in the past, solutions to decrease the code review lifetime are less understood. This study investigates the code review process to quantify delays and investigate opportunities to potentially increase code velocity.We study the temporal characteristics of half a million code reviews hosted on Gerrit and Phabricator, starting from the first response, to a decision to accept or reject the changes, and until the changes are merged into a target branch. We identified two types of time delays: (a) the wait time from the proposal of code changes until first response, and (b) the wait time between acceptance and merging. Our study indicates that reducing the time between acceptance and merging has the potential to speed up Phabricator code reviews by 29\u201363%. Small code changes and changes made by authors with a large number of previously accepted code reviews have a higher chance of being immediately accepted, without code review iterations. Our analysis suggests that switching from manual to automatic merges can help increase code velocity.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Aditya Kumar",
                "institution": "Snap, Inc.",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": "United States"
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "LineVD: Statement-level Vulnerability Detection using Graph Neural Networks",
        "topics": "Technical Papers",
        "abstract": "Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development workflow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experiments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art.",
        "authors": [
            {
                "name": "David Hin",
                "institution": "The University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Andrey Kan",
                "institution": "The University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Huaming Chen",
                "institution": "The University of Adelaide",
                "country": "Australia"
            },
            {
                "name": "Muhammad Ali Babar",
                "institution": "University of Adelaide",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses",
        "topics": "Technical Papers",
        "abstract": "Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that isgeneric. To this end, we propose thefirst self-supervised pre-trainingapproach (called GraphCode2Vec) which produces task-agnostic embedding of lexical and program dependence features. GraphCode2Vec achieves this via a synergistic combination ofcode analysisandGraph Neural Networks. GraphCode2Vec isgeneric, itallows pre-training, and it isapplicable to several SE downstream tasks. We evaluate the effectiveness of GraphCode2Vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarlygenericcode embedding baselines (Code2Seq, Code2Vec, CodeBERT, GraphCodeBERT) and7 task-specific, learning-based methods. In particular, GraphCode2Vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that GraphCode2Vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness.",
        "authors": [
            {
                "name": "Wei Ma",
                "institution": "SnT, University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Mengjie Zhao",
                "institution": "LMU Munich",
                "country": "Germany"
            },
            {
                "name": "Ezekiel Soremekun",
                "institution": "SnT, University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Qiang Hu",
                "institution": "University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Jie M. Zhang",
                "institution": "King's College London",
                "country": "United Kingdom"
            },
            {
                "name": "Mike Papadakis",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Maxime Cordy",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Xiaofei Xie",
                "institution": "Singapore Management University, Singapore",
                "country": "Singapore"
            },
            {
                "name": "Yves Le Traon",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            }
        ]
    },
    {
        "title": "Is GitHub's Copilot as Bad As Humans at Introducing Vulnerabilities in Code?",
        "topics": "Registered Reports",
        "abstract": "Several advances in deep learning have been successfully applied to the software development process. Of recent interest is the use of neural language models to build tools that can assist in writing code. There is a growing body of work to evaluate these tools and their underlying language models. We aim to contribute to this line of research via a comparative empirical analysis of these tools and language models from a security perspective. For the rest of this paper, we use CGT (Code Generation Tool) to refer to language models as well as other tools, such as Copilot, that are built with language models.",
        "authors": [
            {
                "name": "Owura Asare",
                "institution": "University of Waterloo",
                "country": "Canada"
            },
            {
                "name": "Mei Nagappan",
                "institution": "University of Waterloo",
                "country": "Canada"
            },
            {
                "name": "N. Asokan",
                "institution": "University of Waterloo",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "LAGOON: An Analysis Tool for Open Source Communities",
        "topics": "Data and Tool Showcase Track",
        "abstract": "This paper presents LAGOON \u2013 an open source platform for understanding the complex ecosystems of Open Source Software (OSS) communities. The platform currently utilizes spatiotemporal graphs to store and investigate the artifacts produced by these communities, and help analysts identify bad actors who might compromise an OSS project\u2019s security. LAGOON provides ingest of artifacts from several common sources, including source code repositories, issue trackers, mailing lists and scraping content from project websites. Ingestion utilizes a modular architecture, which supports incremental updates from data sources and provides a generic identity fusion process that can recognize the same community members across disparate accounts. A user interface is provided for visualization and exploration of an OSS project\u2019s complete sociotechnical graph. Scripts are provided for applying machine learning to identify patterns within the data. While current focus is on the identification of bad actors in the Python community, the platform\u2019s reusability makes it easily extensible with new data and analyses, paving the way for LAGOON to become a comprehensive means of assessing various OSS-based projects and their communities.",
        "authors": [
            {
                "name": "Sourya Dey",
                "institution": "Galois, Inc.",
                "country": null
            },
            {
                "name": "Walt Woods",
                "institution": "Galois, Inc.",
                "country": null
            }
        ]
    },
    {
        "title": "ECench: An Energy Bug Benchmark of Ethereum Client Software",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Ethereum is the most popular blockchain network because of the introduction of a smart contract. While Ethereum-based software has significantly increased in the wake of their popularity, the carbon emitted by them is pointed to as a global issue.To reduce the emission of carbon, it is necessary to reduce the energy consumed by the software. Recently, most studies have focused on the smart contract and then proposed energy efficiency methods for carbon friendly Ethereum networks. However, it is required to review not only smart contract but also client software for energy used in Ethereum network. This is because the client software performs all functions occurring in Ethereum network that includes smart contracts. Therefore, we need to investigate energy bugs that waste energy in the Ethereum client software, and then study to solve these bugs. The first task to make these studies possible is to build the energy bug benchmark of Ethereum client software. This paper introduces ECench, an energy bug benchmark of Ethereum client software. ECench includes 507 energy buggy commits from 7 series  of client software that are nomally operated in Ethereum network. We carefully collected and manually reviewed them for the more clean commits. Another key strength of our benchmark is to provide the 8 categories which cause energy wastage. These categories can serve as a cornerstone for researchers to identify energy waste codes. Consequently, it can provide a valuable starting point for studies for energy reduction, further carbon reduction, in Ethereum.",
        "authors": [
            {
                "name": "Jinyoung Kim",
                "institution": "Sungkyunkwan University",
                "country": "South Korea"
            },
            {
                "name": "Misoo Kim",
                "institution": "Sungkyunkwan University",
                "country": "South Korea"
            },
            {
                "name": "Eunseok Lee",
                "institution": "Sungkyunkwan University",
                "country": "South Korea"
            }
        ]
    },
    {
        "title": "Back to the future: Empirical Revolution(s) in Software Engineering",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Audris Mockus",
                "institution": "The University of Tennessee",
                "country": null
            }
        ]
    },
    {
        "title": "Bot Detection in GitHub Repositories",
        "topics": "Hackathon",
        "abstract": "Contemporary social coding platforms like GitHub promote collaborative development. Many open-source software repositories hosted in these platforms use machine accounts (bots) to automate and facilitate a wide range of effort-intensive and repetitive activities. Determining if an account corresponds to a bot or a human contributor is important for socio-technical development analytics, for example, to understand how humans collaborate and interact in the presence of bots, to assess the positive and negative impact of using bots, to identify the top project contributors, to identify potential bus factors, and so on. Our project aims to include the trained machine learning (ML) classifier from the BoDeGHa bot detection tool as a plugin to the Grimoirelab development analytics platform. In this work we present the procedure to form a pipeline for retrieving contribution and contributor data using Perceval, distinguishing bots from humans using BoDeGHa, and visualising the results using a Kibana dashboard.",
        "authors": [
            {
                "name": "Natarajan Chidambaram",
                "institution": "University of Mons",
                "country": "Belgium"
            },
            {
                "name": "Pooya Rostami Mazrae",
                "institution": "University of Mons",
                "country": "Belgium"
            }
        ]
    },
    {
        "title": "Can instability variations warn developers when open-source projects boost?",
        "topics": "Registered Reports",
        "abstract": "Although architecture instability has been studied and measured using a variety of metrics, a deeper analysis of which project parts are less stable and how such instability varies over time is still needed. While having more information on architecture instability is, in general, useful for any software development project, it is especially important in Open Source Software (OSS) projects where the supervision of the development process is more difficult to achieve. In particular, we are interested when OSS projects grow from a small controlled environment (i.e., the cathedral phase) to a community-driven project (i.e., the bazaar phase). In such a transition, the project often explodes in terms of software size and number of contributing developers. Hence, the complexity of the newly added features, and the frequency of the commits and files modified may cause significant variations of the instability of the structure of the classes and packages. Consequently, in this registered report we suggest ways to analyze the instability in OSS projects, especially during that sensitive phase where they become community-driven. We intend to suggest ways to predict the evolution of the instability in several OSS projects. Our preliminary results show that it seems possible to provide meaningful estimations that can be useful for OSS teams before a project grows in excess.",
        "authors": [
            {
                "name": "Alejandro Valezate",
                "institution": "Rey Juan Carlos University",
                "country": "Spain"
            },
            {
                "name": "Rafael Capilla",
                "institution": "Universidad Rey Juan Carlos",
                "country": "Spain"
            },
            {
                "name": "Gregorio Robles",
                "institution": "Universidad Rey Juan Carlos",
                "country": "Spain"
            },
            {
                "name": "Victor Salamanca",
                "institution": "Rey Juan Carlos University",
                "country": "Spain"
            }
        ]
    },
    {
        "title": "Is Open Source Eating the World\u2019s Software? Measuring the Proportion of Open Source in proprietary software using Java Binaries",
        "topics": "Technical Papers",
        "abstract": "That open source software comprises an increasingly large percentage of modern software applications has become conventional wisdom. The exact extent to which open source software constitutes today\u2019s applications is indeterminate, however, at least by the standards of the academic software engineering research community. This paper proposes a methodology and associated tool that can analyze Java binaries and determine the proportion of open source that compose it.",
        "authors": [
            {
                "name": "Julius Musseau",
                "institution": "Mergebase",
                "country": null
            },
            {
                "name": "John Speed Meyers",
                "institution": "Chainguard",
                "country": null
            },
            {
                "name": "George P. Sieniawski",
                "institution": "IQT Labs",
                "country": null
            },
            {
                "name": "C. Albert Thompson",
                "institution": "Ford Motor Company",
                "country": null
            },
            {
                "name": "Daniel M. German",
                "institution": "University of Victoria",
                "country": null
            }
        ]
    },
    {
        "title": "From Models to Systems: Rethinking the Role of Software Engineering for Machine Learning",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Christian K\u00e4stner",
                "institution": "Carnegie Mellon University",
                "country": null
            }
        ]
    },
    {
        "title": "Engineering the MSR Field and the Joy of Research",
        "topics": "Technical Papers",
        "abstract": null,
        "authors": [
            {
                "name": "Ahmed E. Hassan",
                "institution": "Queen's University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Software Bots in Software Engineering: Benefits and Challenges",
        "topics": "Tutorials",
        "abstract": null,
        "authors": [
            {
                "name": "Mairieli Wessel",
                "institution": "Delft University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Marco Gerosa",
                "institution": "Northern Arizona University, USA",
                "country": "United States"
            },
            {
                "name": "Emad Shihab",
                "institution": "Concordia University",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "A Versatile Dataset of Agile Open Source Software Projects",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Agile software development is nowadays a widely adopted practise in both open-source and industrial software projects. Agile teams typically heavily rely on issue management tools to document new issues and keep track of outstanding ones, in addition to storing their technical details, effort estimates, assignment to developers, and more. Previous work utilised the historical information stored in issue management systems for various purposes; however, when researchers make their empirical data public, it is usually relevant solely to the study\u2019s objective. In this paper, we present a more holistic and versatile dataset containing a wealth of information on more than 480,000 issues from 44 open-source Agile software, making it well-suited to several research avenues, and cross-analyses therein, including effort estimation, issue prioritization, issue assignment and many more. We make this data publicly available on GitHub to facilitate ease of use, maintenance, and extensibility.",
        "authors": [
            {
                "name": "Vali Tawosi",
                "institution": "University College London",
                "country": "United Kingdom"
            },
            {
                "name": "Afnan Al-Subaihin",
                "institution": "University College London",
                "country": "United Kingdom"
            },
            {
                "name": "Rebecca Moussa",
                "institution": "University College London",
                "country": "United Kingdom"
            },
            {
                "name": "Federica Sarro",
                "institution": "University College London",
                "country": "United Kingdom"
            }
        ]
    },
    {
        "title": "Methods for Stabilizing Models across Large Samples of Projects(with case studies on Predicting Defect and Project Health)",
        "topics": "Technical Papers",
        "abstract": "Despite decades of research,   SE   lacks widely accepted models (that offer precise quantitative stable predictions) about what factors most influence software quality. This paper provides a promising result showing such stable models can be generated using a new transfer learning framework called \u201cSTABILIZER\u201d. Given a tree of recursively clustered projects (using project meta-data), STABILIZER promotes a model upwards if it performs best in the lower clusters (stopping when the promoted model performs worse than the models seen at a lower level).",
        "authors": [
            {
                "name": "Suvodeep Majumder",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tianpei Xia",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Rahul Krishna",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tim Menzies",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "A Large-scale Dataset of (Open Source) License Text Variants",
        "topics": "Data and Tool Showcase Track",
        "abstract": "We introduce a large-scale dataset of the complete texts of free/open source software (FOSS) license variants. To assemble it we have collected from the Software Heritage archive\u2014the largest publicly available archive of FOSS source code with accompanying development history\u2014all versions of files whose names are commonly used to convey licensing terms to software users and developers. The dataset consists of 6.5 million unique license files that can be used to conduct empirical studies on open source licensing, training of automated license classifiers, natural language processing (NLP) analyses of legal texts, as well as historical and phylogenetic studies on FOSS licensing. Additional metadata about shipped license files are also provided, making the dataset ready to use in various contexts; they include: file length measures, detected MIME type, detected SPDX license (using ScanCode), example origin (e.g., GitHub repository), oldest public commit in which the license appeared. The dataset is released as open data as an archive file containing all deduplicated license blobs, plus several portable CSV files for metadata, referencing blobs via cryptographic checksums.",
        "authors": [
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "SECOM: Towards a convention for security commit messages",
        "topics": "Industry Track",
        "abstract": "Context. Detecting and especially assessing software vulnerabilities continues to be a challenge in the vulnerability prediction field mainly due to the poor quality and/or low amount of data curated [1]. Many works were conducted aiming to create datasets of security patches based on software repositories data [2,3,4,5]. However, there are still very few known gold standard datasets for comparison/evaluation of the different approaches [6]. One way to detect/assess software vulnerabilities is by extracting security-related information from commit messages. Yet, automating the detection and assessment of vulnerabilities upon security commit messages is still challenging due to the lack of structured and clear messages.",
        "authors": [
            {
                "name": "Sofia Reis",
                "institution": "Instituto Superior T\u00e9cnico, U. Lisboa & INESC-ID",
                "country": "Portugal"
            },
            {
                "name": "Rui Abreu",
                "institution": "Faculty of Engineering, University of Porto",
                "country": "Portugal"
            },
            {
                "name": "Hakan Erdogmus",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Corina S. P\u0103s\u0103reanu",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Detecting Privacy-Sensitive Code Changes with Language Modeling",
        "topics": "Industry Track",
        "abstract": null,
        "authors": [
            {
                "name": "G\u00f6kalp Demirci",
                "institution": "Meta Platforms, Inc.",
                "country": "United States"
            },
            {
                "name": "Vijayaraghavan Murali",
                "institution": "Meta Platforms, Inc.",
                "country": "United States"
            },
            {
                "name": "Imad Ahmad",
                "institution": "Meta Platforms, Inc.",
                "country": "United States"
            },
            {
                "name": "Rajeev Rao",
                "institution": "Meta Platforms, Inc.",
                "country": "United States"
            },
            {
                "name": "Gareth Ari Aye",
                "institution": "Meta Platforms, Inc.",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Extracting corrective actions from code repositories",
        "topics": "Industry Track",
        "abstract": "This industrial problem aims  to determine and structure, in a suitable taxonomy, the most common anomalies and related corrective actions present in software development starting from information stored in code repositories.",
        "authors": [
            {
                "name": "Yegor Bugayenko",
                "institution": "Huawei",
                "country": "Russia"
            },
            {
                "name": "Kirill Daniakin",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Mirko Farina",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Firas Jolha",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Artem Kruglov",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Witold Pedrycz",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Giancarlo Succi",
                "institution": "Innopolis University",
                "country": "Russia"
            }
        ]
    },
    {
        "title": "Problems and Solutions in Applying Continuous Integration and Delivery to 20 Open-Source Cyber-Physical Systems",
        "topics": "Technical Papers",
        "abstract": "Continuous integration and delivery (CI/CD) has been shown to be very useful to improve the quality of software products (e.g., increasing their reliability or maintainability), and their development processes, e.g., by shortening release cycles. Applying CI/CD in the context of Cyber-Physical Systems (CPSs) can be  particularly important, given that many of those systems can have safety-critical properties, and given their interaction with hardware or simulators during the development phase. This paper empirically analyzes how CI/CD is enacted in CPSs when considering the context of open-source projects, that often (also) rely on hosted CI/CD solutions, and benefit of an open-source development community. We qualitatively analyze a statistically significant sample of 670 pull requests from 20  open-source CPSs hosted on  GitHub, to identify and categorize\u2014also keeping into account catalogs from previous literature\u2014bad practices, challenges, mitigation and restructuring actions. The study reports and discusses the relationships we found between bad practices/challenges and CI/CD restructuring/mitigation strategies, reporting concrete examples, especially those emerging from the intrinsic complexity of CPSs.",
        "authors": [
            {
                "name": "Fiorella Zampetti",
                "institution": "University of Sannio",
                "country": "Italy"
            },
            {
                "name": "Vittoria Nardone",
                "institution": "University of Sannio",
                "country": "Italy"
            },
            {
                "name": "Massimiliano Di Penta",
                "institution": "University of Sannio",
                "country": "Italy"
            }
        ]
    },
    {
        "title": "Finding the Fun in Fundraising: Public Issues and Pull Requests in VC-backed Open-Core Companies",
        "topics": "Industry Track",
        "abstract": "GitHub\u2019s mission is to accelerate human progress through developer collaboration. To better understand how well we\u2019re achieving this mission, it\u2019s crucial to investigate the off-platform effects of on-platform activity. In this lightning talk, I will present my explorations of the social dynamics of a handful of venture-backed open-core companies using GitHub data, with the hope of inspiring future research collaborations on questions of the societal impact of open source.",
        "authors": [
            {
                "name": "Kevin Xu",
                "institution": "GitHub",
                "country": null
            }
        ]
    },
    {
        "title": "GitRank: A Framework to Rank GitHub Repositories",
        "topics": "Hackathon",
        "abstract": "Open-source repositories provide wealth of information and are increasingly being used to build artificial intelligence (AI) based systems to solve problems in software engineering. Open-source repositories could be of varying quality levels, and bad-quality repositories could degrade performance of these systems. Evaluating quality of open-source repositories, which is not available directly on code hosting sites such as GitHub, is thus important. In this hackathon, we utilize known code quality measures and GrimoireLab toolkit to implement a framework, named GitRank, to rank open-source repositories on three different criteria. We discuss our findings and preliminary evaluation of GitRank in this hackathon report.",
        "authors": [
            {
                "name": "Niranjan Hasabnis",
                "institution": "Intel Labs",
                "country": "United States"
            }
        ]
    },
    {
        "title": "LAGOON: An Analysis Tool for Open Source Communities",
        "topics": "Data and Tool Showcase Track",
        "abstract": "This paper presents LAGOON \u2013 an open source platform for understanding the complex ecosystems of Open Source Software (OSS) communities. The platform currently utilizes spatiotemporal graphs to store and investigate the artifacts produced by these communities, and help analysts identify bad actors who might compromise an OSS project\u2019s security. LAGOON provides ingest of artifacts from several common sources, including source code repositories, issue trackers, mailing lists and scraping content from project websites. Ingestion utilizes a modular architecture, which supports incremental updates from data sources and provides a generic identity fusion process that can recognize the same community members across disparate accounts. A user interface is provided for visualization and exploration of an OSS project\u2019s complete sociotechnical graph. Scripts are provided for applying machine learning to identify patterns within the data. While current focus is on the identification of bad actors in the Python community, the platform\u2019s reusability makes it easily extensible with new data and analyses, paving the way for LAGOON to become a comprehensive means of assessing various OSS-based projects and their communities.",
        "authors": [
            {
                "name": "Sourya Dey",
                "institution": "Galois, Inc.",
                "country": null
            },
            {
                "name": "Walt Woods",
                "institution": "Galois, Inc.",
                "country": null
            }
        ]
    },
    {
        "title": "TwinDroid: A Dataset of Android app System call traces and Trace Generation Pipeline",
        "topics": "Data and Tool Showcase Track",
        "abstract": "System call traces are an invaluable source of information about a program\u2019s runtime behavior, and have been shown to be particularly useful for malware detection in Android apps. However, the paucity of publicly available high quality dataset hinders the development of the field. In this paper, we introduce TwinDroid, a dataset of over 1000 system calls traces, from both benign and infected Android apps. A large part of the dataset is composed of traces from pairs benign and infected apps, identical apart from the inclusion of malware in the latter. This makes TwinDroid an ideal basis for security research, and an earlier version of TwinDroid has already been used for this purpose.   In addition to a dataset of traces, TwinDroid includes a fully automated traces generation pipeline, which allows users to seamlessly generate new traces in a standardized manner. This pipeline will allow the dataset to remain up-to-date and relevant despite the rapid pace of change that characterizes Android security.",
        "authors": [
            {
                "name": "Asma Razgallah",
                "institution": "Universit\u00e9 du Qu\u00e9bec \u00e0 Chicoutimi",
                "country": "Canada"
            },
            {
                "name": "Raphael Khoury",
                "institution": "Universit\u00e9 du Qu\u00e9bec \u00e0 Chicoutimi",
                "country": "Canada"
            },
            {
                "name": "Jean-Baptiste Poulet",
                "institution": "Universit\u00e9 du Qu\u00e9bec \u00e0 Chicoutimi",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Towards Understanding Barriers and Mitigation Strategies of Software Engineers with Non-traditional Educational and Occupational Backgrounds",
        "topics": "Registered Reports",
        "abstract": "The traditional path to a software engineering career involves a post-secondary diploma in Software Engineering, Computer Science, or a related field. However, many software engineers take a non-traditional path to their career, starting from other industries or fields of study. This paper proposes a study on barriers faced by software engineers with non-traditional educational and occupational backgrounds, and possible mitigation strategies for those barriers. We propose a two-stage methodology, consisting of an exploratory study, followed by a validation study. The exploratory study will involve a grounded-theory-based qualitative analysis of relevant Reddit data to yield a framework around the barriers and possible mitigation strategies. These findings will then be validated using a survey in the validation study. Making software engineering more accessible to those with non-traditional backgrounds will not only bring about the benefits of functional diversity, but also serves as a method of filling in the labour shortages of the software engineering industry.",
        "authors": [
            {
                "name": "Tavian Barnes",
                "institution": "University of Waterloo",
                "country": null
            },
            {
                "name": "Ken Jen Lee",
                "institution": "University of Waterloo",
                "country": null
            },
            {
                "name": "Cristina Tavares",
                "institution": "University of Waterloo",
                "country": null
            },
            {
                "name": "Gema Rodr\u00edguez-P\u00e9rez",
                "institution": "University of British Columbia (UBC)",
                "country": "Canada"
            },
            {
                "name": "Mei Nagappan",
                "institution": "University of Waterloo",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Do Small Code Changes Merge Faster? A Multi-Language Empirical Investigation",
        "topics": "Technical Papers",
        "abstract": "Code velocity, or the speed with which code changes are integrated into a production environment, plays a crucial role in Continuous Integration and Continuous Deployment. Many studies report factors influencing code velocity. However, solutions to increase code velocity are unclear. Meanwhile, the industry continues to issue guidelines on \u201cideal\u201d code change size, believing it increases code velocity despite lacking evidence validating the practice. Surprisingly, this fundamental question has not been studied to date. This study investigates the practicality of improving code velocity by optimizing pull request size and composition(ratio of insertions, deletions, and modifications). We start with a hypothesis that a moderate correlation exists between pull request size and time-to-merge. We selected 100 most popular, actively developed projects from 10 programming languages on GitHub. We analyzed our dataset of 845,316 pull requests by size, composition, and context to explore its relationship to time-to-merge\u2014a proxy to measure code velocity. Our study shows that pull request size and composition do not relate to time-to-merge. Regardless of the contextual factors that can influence pull request size or composition (e.g., programming language), the observation holds. Pull request data from two other platforms: Gerrit and Phabricator (401,790 code reviews) confirms the lack of relationship. This negative result as in \u201c\u2026 eliminate useless hypotheses \u2026 \u201d [73] challenges a widespread belief by showing that small code changes do not merge faster to increase code velocity.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": "United States"
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Using Datalore for Reproducible Research",
        "topics": "Tutorials",
        "abstract": null,
        "authors": [
            {
                "name": "Jodie Burchell",
                "institution": "JetBrains",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "LineVul: A Transformer-based Line-Level Vulnerability Prediction",
        "topics": "Technical Papers",
        "abstract": "Software vulnerabilities are prevalent in software systems, causing a variety of problems including deadlock, information loss, or system failures. Thus, early predictions of software vulnerabilities are critically important in safety-critical software systems. Various ML/DL-based approaches have been proposed to predict vulnerabilities at the file/function/method level. Recently, IVDetect (a graph-based neural network) is proposed to predict vulnerabilities at the function level. Yet, the IVDetect approach is still inaccurate and coarse-grained. In this paper, we propose LineVul, a Transformer-based line-level vulnerability prediction approach in order to address several limitations of the state-of-the-art IVDetect approach. Through an empirical evaluation of a large-scale real-world dataset with 188k+ C/C++ functions, we show that LineVul achieves (1) 160%-379% higher F1-measure for function-level predictions; (2) 12%-25% higher Top-10 Accuracy for line-level predictions; and (3) 29%-53% less Effort@20%Recall than the state-of-the-art approaches. The substantial improvement of our approach highlights the significant contributions towards more accurate, more cost-effective, and more finer-grained software vulnerability predictions.",
        "authors": [
            {
                "name": "Michael Fu",
                "institution": "Monash University",
                "country": "Australia"
            },
            {
                "name": "Kla Tantithamthavorn",
                "institution": "Monash University",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "OpenSSL 3.0.0: An exploratory case study",
        "topics": "Hackathon",
        "abstract": "Version 3.0.0 of OpenSSL was the first release built with public design documents. We compare code quality of this version with the previous major release using a new backend for Graal that we developed during the Hackathon. We find that while code quality improved for both releases during their development, the improvements were larger for version 3.0.0. However, consistency of coding style decreased faster during development of the current version.",
        "authors": [
            {
                "name": "James Walden",
                "institution": "Northern Kentucky University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "To Type or Not to Type? A Systematic Comparison of the Software Quality of JavaScript and TypeScript Applications on GitHub",
        "topics": "Technical Papers",
        "abstract": "JavaScript (JS) is one of the most popular programming languages, and widely used for web apps, mobile apps, desktop clients, and even backend development. Due to its dynamic and flexible nature, however, JS applications often have a reputation for poor software quality. As a type-safe superset of JavaScript, TypeScript (TS) offers features to address these prejudices. However, there is currently insufficient empirical evidence to broadly support the claim that TS applications exhibit better software quality than JS applications.",
        "authors": [
            {
                "name": "Justus Bogner",
                "institution": "University of Stuttgart, Institute of Software Engineering, Empirical Software Engineering Group",
                "country": "Germany"
            },
            {
                "name": "Manuel Merkel",
                "institution": "University of Stuttgart",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "Evaluating few shot and Contrastive learning Methods for Code Clone Detection",
        "topics": "Registered Reports",
        "abstract": "Context:Code Clone Detection (CCD) is a software engineering task that is used for plagiarism detection, code search, and code comprehension. Recently, deep learning-based models have achieved an F1 score (a metric used to assess classifiers) of $\\sim$95% on the CodeXGLUE benchmark. These models require many training data, mainly fine-tuned on Java or C++ datasets. However, no previous study evaluates the generalizability of these models where a limited amount of annotated data is available.",
        "authors": [
            {
                "name": "Mohamad Khajezade",
                "institution": "University of British Columbia",
                "country": "Canada"
            },
            {
                "name": "Fatemeh Hendijani Fard",
                "institution": "University of British Columbia",
                "country": "Canada"
            },
            {
                "name": "Mohamed S Shehata",
                "institution": "University of British Columbia",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Code Review Practices for Refactoring Changes: An Empirical Study on OpenStack",
        "topics": "Technical Papers",
        "abstract": "Modern code review is a widely used technique employed in both industrial and open-source projects to improve software quality, share knowledge, and ensure adherence to coding standards and guidelines. During code review, developers may discuss refactoring activities before merging code changes in the codebase. To date, code review has been extensively studied to explore its general challenges, best practices and outcomes, and socio-technical aspects. However, little is known about how refactoring is being reviewed and what developers care about when they review refactored code. Hence, in this work, we present a quantitative and qualitative study to understand what are the main criteria developers rely on to develop a decision about accepting or rejecting a submitted refactored code, and what makes this process challenging. Through a case study of 11,010 refactoring and non-refactoring reviews spread across OpenStack open-source projects, we find that refactoring-related code reviews take significantly longer to be resolved in terms of code review efforts. Moreover, upon performing a thematic analysis on a significant sample of the refactoring code review discussions, we built a comprehensive taxonomy consisting of 28 refactoring review criteria in the context of MCR. We envision our findings reaffirming the necessity of developing accurate and efficient tools and techniques that can assist developers in the review process in the presence of refactorings.",
        "authors": [
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Moataz Chouchen",
                "institution": "ETS",
                "country": "Canada"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Evaluating the effectiveness of local explanation methods on source code-based defect prediction models",
        "topics": "Technical Papers",
        "abstract": "Interpretation has been considered as one of key factors for applying defect prediction in practice. As one way for interpretation, local explanation methods has been widely used for certain predictions on datasets of traditional features. There are also attempts to use local explanation methods on source code-based defect prediction models, but unfortunately, it will get poor results. Since it is unclear how effective those local explanation methods are, we evaluate such methods with automatic metrics which focus on local faithfulness and explanation precision. Based on the results of experiments, we find that the effectiveness of local explanation methods depends on the adopted defect prediction models. They are effective on Bag of Word-based models, while they may not be effective enough to explain all predictions of deep semantic models. Besides, we also find that the hyperparameter of local explanation methods should be carefully optimized to get more precise and meaningful explanation",
        "authors": [
            {
                "name": "Yuxiang Gao",
                "institution": "Jiangsu Normal University",
                "country": null
            },
            {
                "name": "Yi Zhu",
                "institution": "Jiangsu Normal University",
                "country": null
            },
            {
                "name": "Qiao YU",
                "institution": "Jiangsu Normal University",
                "country": null
            }
        ]
    },
    {
        "title": "A Time Series-Based Dataset of Open-Source Software Evolution",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Software evolution is the process of developing, maintaining, and updating software systems. It is known that the software systems tend to increase their complexity and size over their evolution to meet the demands required by the users. Due to this fact, researchers have increasingly carried out studies on software evolution to understand the systems\u2019 evolution pattern and propose techniques to overcome inherent problems in software evolution. Many of these works collect data but do not make them publicly available. Many datasets on software evolution are outdated, and/or are small, and some of them do not provide time series from software metrics. We propose an extensive software evolution dataset with temporal information about open-source Java systems. To build this dataset, we proposed a methodology of four steps: selecting the systems using a criterion, extracting and measuring their releases, and generating their time series. Our dataset contains time series of 46 software metrics extracted from 46 open-source Java systems, and we make it publicly available.",
        "authors": [
            {
                "name": "Bruno L. Sousa",
                "institution": "UFMG",
                "country": "Brazil"
            },
            {
                "name": "Mariza Bigonha",
                "institution": "Professor at Federal University of Minas Gerais",
                "country": "Brazil"
            },
            {
                "name": "Kecia A. M. Ferreira",
                "institution": "CEFET-MG",
                "country": "Brazil"
            },
            {
                "name": "Glaura C. Franco",
                "institution": "UFMG",
                "country": "Brazil"
            }
        ]
    },
    {
        "title": "Mining Code Review Data to Understand Waiting Times Between Acceptance and Merging: An Empirical Analysis",
        "topics": "Technical Papers",
        "abstract": "Increasing code velocity (or the speed with which code changes are reviewed and merged) is integral to speeding up development and contributes to the work satisfaction of engineers. While factors affecting code change acceptance have been investigated in the past, solutions to decrease the code review lifetime are less understood. This study investigates the code review process to quantify delays and investigate opportunities to potentially increase code velocity.We study the temporal characteristics of half a million code reviews hosted on Gerrit and Phabricator, starting from the first response, to a decision to accept or reject the changes, and until the changes are merged into a target branch. We identified two types of time delays: (a) the wait time from the proposal of code changes until first response, and (b) the wait time between acceptance and merging. Our study indicates that reducing the time between acceptance and merging has the potential to speed up Phabricator code reviews by 29\u201363%. Small code changes and changes made by authors with a large number of previously accepted code reviews have a higher chance of being immediately accepted, without code review iterations. Our analysis suggests that switching from manual to automatic merges can help increase code velocity.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Aditya Kumar",
                "institution": "Snap, Inc.",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": "United States"
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Do Small Code Changes Merge Faster? A Multi-Language Empirical Investigation",
        "topics": "Technical Papers",
        "abstract": "Code velocity, or the speed with which code changes are integrated into a production environment, plays a crucial role in Continuous Integration and Continuous Deployment. Many studies report factors influencing code velocity. However, solutions to increase code velocity are unclear. Meanwhile, the industry continues to issue guidelines on \u201cideal\u201d code change size, believing it increases code velocity despite lacking evidence validating the practice. Surprisingly, this fundamental question has not been studied to date. This study investigates the practicality of improving code velocity by optimizing pull request size and composition(ratio of insertions, deletions, and modifications). We start with a hypothesis that a moderate correlation exists between pull request size and time-to-merge. We selected 100 most popular, actively developed projects from 10 programming languages on GitHub. We analyzed our dataset of 845,316 pull requests by size, composition, and context to explore its relationship to time-to-merge\u2014a proxy to measure code velocity. Our study shows that pull request size and composition do not relate to time-to-merge. Regardless of the contextual factors that can influence pull request size or composition (e.g., programming language), the observation holds. Pull request data from two other platforms: Gerrit and Phabricator (401,790 code reviews) confirms the lack of relationship. This negative result as in \u201c\u2026 eliminate useless hypotheses \u2026 \u201d [73] challenges a widespread belief by showing that small code changes do not merge faster to increase code velocity.",
        "authors": [
            {
                "name": "Gunnar Kudrjavets",
                "institution": "University of Groningen",
                "country": "United States"
            },
            {
                "name": "Nachiappan Nagappan",
                "institution": "Microsoft Research",
                "country": null
            },
            {
                "name": "Ayushi Rastogi",
                "institution": "University of Groningen, The Netherlands",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Using Bandit Algorithms for Selecting Feature Reduction Techniques in Software Defect Prediction",
        "topics": "Technical Papers",
        "abstract": "Background: Selecting a suitable feature reduction technique, when building a defect prediction model, can be challenging. Different techniques can result in the selection of different independent variables which have an impact on the overall performance of the prediction model. To help in the selection, previous studies have assessed the impact of each feature reduction technique using different datasets. However, there are many reduction techniques, and therefore some of the well-known techniques have not been assessed by those studies. Aim: The goal of the study is to select a high-accuracy reduction technique from several candidates without preliminary assessments. Method: We utilized bandit algorithm (BA) to help with the selection of best features reduction technique for a list of candidates. To select the best feature reduction technique, BA evaluates the prediction accuracy of the candidates, comparing testing results of different modules with their prediction results. By substituting the reduction technique for the prediction method, BA can then be used to select the best reduction technique. Results: In the experiment, we evaluated the performance of BA to select suitable reduction technique. We performed cross version defect prediction using 14 datasets. As feature reduction techniques, we used two assessed and two non-assessed techniques. Using BA, the prediction accuracy was higher or equivalent than existing approaches on average, compared with techniques selected based on an assessment. Conclusions: BA can have larger impact on improving prediction models by helping not only on selecting suitable models, but also in selecting suitable feature reduction techniques.",
        "authors": [
            {
                "name": "Masateru Tsunoda",
                "institution": "Kindai University",
                "country": "Japan"
            },
            {
                "name": "Akito Monden",
                "institution": "Okayama University",
                "country": "Japan"
            },
            {
                "name": "Koji Toda",
                "institution": "Fukuoka Institute of Technology",
                "country": "Japan"
            },
            {
                "name": "Amjed Tahir",
                "institution": "Massey University",
                "country": "New Zealand"
            },
            {
                "name": "Kwabena Ebo Bennin",
                "institution": "Wageningen University and Research",
                "country": "Netherlands"
            },
            {
                "name": "Keitaro Nakasai",
                "institution": "National Institute of Technology, Kagoshima College",
                "country": "Japan"
            },
            {
                "name": "Masataka Nagura",
                "institution": "Nanzan University",
                "country": "Japan"
            },
            {
                "name": "Kenichi Matsumoto",
                "institution": "Nara Institute of Science and Technology",
                "country": "Japan"
            }
        ]
    },
    {
        "title": "Varangian: A Git Bot for Augmented Static Analysis",
        "topics": "Industry Track",
        "abstract": "The complexity and scale of modern software programs often lead to overlooked programming errors and security vulnerabilities. Developers often rely on automatic tools, like static analysis tools, to look for bugs and vulnerabilities. Static analysis tools are widely used because they can understand nontrivial program behaviors, scale to millions of lines of code, and detect subtle bugs. However, they are known to generate an excess of false alarms which hinder their utilization as it is counterproductive for developers to go through a long list of reported issues, only to find a few true positives. One of the ways proposed to suppress false positives is to use machine learning to identify them. However, training machine learning models requires good quality labeled datasets. For this purpose, we developed D2A , a differential analysis based approach that uses the commit history of a code repository to create a labeled dataset of Infer  static analysis output.",
        "authors": [
            {
                "name": "Saurabh Pujar",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Yunhui Zheng",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Luca Buratti",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Burn Lewis",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Alessandro Morari",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Jim A. Laredo",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Kevin Postlethwait",
                "institution": "Red Hat",
                "country": null
            },
            {
                "name": "Christoph G\u00f6rn",
                "institution": "Red Hat",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses",
        "topics": "Technical Papers",
        "abstract": "Code embedding is a keystone in the application of machine learning on several Software Engineering (SE) tasks. To effectively support a plethora of SE tasks, the embedding needs to capture program syntax and semantics in a way that isgeneric. To this end, we propose thefirst self-supervised pre-trainingapproach (called GraphCode2Vec) which produces task-agnostic embedding of lexical and program dependence features. GraphCode2Vec achieves this via a synergistic combination ofcode analysisandGraph Neural Networks. GraphCode2Vec isgeneric, itallows pre-training, and it isapplicable to several SE downstream tasks. We evaluate the effectiveness of GraphCode2Vec on four (4) tasks (method name prediction, solution classification, mutation testing and overfitted patch classification), and compare it with four (4) similarlygenericcode embedding baselines (Code2Seq, Code2Vec, CodeBERT, GraphCodeBERT) and7 task-specific, learning-based methods. In particular, GraphCode2Vec is more effective than both generic and task-specific learning-based baselines. It is also complementary and comparable to GraphCodeBERT (a larger and more complex model). We also demonstrate through a probing and ablation study that GraphCode2Vec learns lexical and program dependence features and that self-supervised pre-training improves effectiveness.",
        "authors": [
            {
                "name": "Wei Ma",
                "institution": "SnT, University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Mengjie Zhao",
                "institution": "LMU Munich",
                "country": "Germany"
            },
            {
                "name": "Ezekiel Soremekun",
                "institution": "SnT, University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Qiang Hu",
                "institution": "University of Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Jie M. Zhang",
                "institution": "King's College London",
                "country": "United Kingdom"
            },
            {
                "name": "Mike Papadakis",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Maxime Cordy",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            },
            {
                "name": "Xiaofei Xie",
                "institution": "Singapore Management University, Singapore",
                "country": "Singapore"
            },
            {
                "name": "Yves Le Traon",
                "institution": "University of Luxembourg, Luxembourg",
                "country": "Luxembourg"
            }
        ]
    },
    {
        "title": "A Deep Study of the Effects and Fixes of Server-Side Request Races in Web Applications",
        "topics": "Technical Papers",
        "abstract": "Nowadays, websites commonly run web applications on the server side to handle HTTP requests and generate responses dynamically. These server-side web applications handle a large number of concurrent requests and are thus highly vulnerable to request races, i.e., races while handling concurrent requests. To better handle such request races in server-side web applications, we need a deep understanding of their characteristics. While some previous studies of real-world request races exist, they primarily focus on the root cause of these bugs. In this paper, we provide a complementary focus on their effects and fixes. We study the external and internal effects of request races, and we relate request-race fixes with concurrency control mechanisms in languages and frameworks for developing server-side web applications. Our study reveals several interesting findings, and we expect our results can help developers better understand request races and guide the design and development of tools for combating request races.",
        "authors": [
            {
                "name": "Zhengyi Qiu",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Shudi Shao",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Qi Zhao",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Hassan Ali Khan",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Xinning Hui",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Guoliang Jin",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "GrimoireLab Maintenance and Evolution",
        "topics": "Hackathon",
        "abstract": "E-type open-source software inevitably grows in size and complexity over time, and without performing anti-regressive tasks this type of software has a limited lifespan. In this project, a case study of the effect of such anti-regressive tasks is conducted using GrimoireLab Graal as a subject. This process is guided by quality metrics and developer insights. The outcome of this work is a life-cycle of maintenance activities, ultimately resulting in a refactored version of GrimoireLab Graal. After applying anti-regressive actions, commonly used software quality metrics decreased (lower is better). Additionally, after performing an experiment to test the evolution readiness of the software, the complexity of the original software increased significantly, whilst no side effects were measured in the revised software.",
        "authors": [
            {
                "name": "Willem Meijer",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "David Visscher",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "Erwin de Haan",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "Merijn Schr\u00f6der",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "Leon Visscher",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "Andrea Capiluppi",
                "institution": "University of Groningen",
                "country": "Netherlands"
            },
            {
                "name": "Ioan Botez",
                "institution": "University of Groningen",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "Automatically Prioritizing and Assigning Tasks from Code Repositories in Puzzle Driven Development",
        "topics": "Industry Track",
        "abstract": "Automatically prioritizing software development tasks extracted from codes could provide significant technical and organizational advantages. Tools exist for the automatic extraction of tasks, but they still lack the ability to capture their mutual dependencies; hence, the capability to prioritize them.",
        "authors": [
            {
                "name": "Ayomide Bakare",
                "institution": "Innopolis University",
                "country": null
            },
            {
                "name": "Yegor Bugayenko",
                "institution": "Huawei",
                "country": "Russia"
            },
            {
                "name": "Arina Cheverda",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Mirko Farina",
                "institution": "Innopolis University",
                "country": null
            },
            {
                "name": "Artem Kruglov",
                "institution": "Innopolis University",
                "country": "Russia"
            },
            {
                "name": "Witold Pedrycz",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Giancarlo Succi",
                "institution": "Innopolis University",
                "country": "Russia"
            }
        ]
    },
    {
        "title": "Microsoft CloudMine: Data Mining for the Executive Order on Improving the Nation\u2019s Cybersecurity",
        "topics": "Industry Track",
        "abstract": "As any other US software maker, Microsoft is bound by the \u201cExecutive Order on Improving the Nation\u2019s Cybersecurity\u201d which dictates a clear mandate to \u201cenhance the software supply chain security\u201d and to generally improve the cyber security practices. To fulfill the executive order, software companies need to enforce new policies and practices on many projects and engineering teams within relatively short periods of time. One challenge is to build up comprehensive inventories of software artifacts which can be tedious and fragile as software eco-systems change rapidly. Required is a system that will constantly monitor and update the inventory of software artifacts and contributors so that at any given point of time. The front line of this security battle includes the product team around the data mining platform CloudMine1 providing the security and compliance teams with engineering artifacts and insights into artifact dependencies and engineering practices of the corresponding engineering teams.",
        "authors": [
            {
                "name": "Kim Herzig",
                "institution": "Tools for Software Engineers",
                "country": "Microsoft"
            },
            {
                "name": "Luke Gostling",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "Maximilian Grothusmann",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "Nora Huang",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "Sascha Just",
                "institution": "Microsoft",
                "country": "Microsoft"
            },
            {
                "name": "n.n.",
                "institution": null,
                "country": null
            },
            {
                "name": "Alan Klimowski",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "Yashasvini Ramkumar",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "Myles McLeroy",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            },
            {
                "name": "K\u0131van\u00e7 Mu\u015flu",
                "institution": "Microsoft",
                "country": "Microsoft"
            },
            {
                "name": "Hitesh Sajnani",
                "institution": "Microsoft",
                "country": "Microsoft"
            },
            {
                "name": "Varsha Vadaga",
                "institution": "Microsoft Corporation",
                "country": "Microsoft"
            }
        ]
    },
    {
        "title": "To What Extent do Deep Learning-based Code Recommenders Generate Predictions by Cloning Code from the Training Set?",
        "topics": "Technical Papers",
        "abstract": "Deep Learning (DL) models have been widely used to support code completion. These models, once properly trained, can take as input an incomplete code component (e.g., an incomplete function) and predict the missing tokens to finalize it. GitHub Copilot is an example of code recommender built by training a DL model on millions of open source repositories: The source code of these repositories acts as training data, allowing the model to learn \u201chow to program\u201d. The usage of such a code is usually regulated by Free and Open Source Software (FOSS) licenses, that establish under which conditions the licensed code can be redistributed or modified. As of Today, it is unclear whether the code generated by DL models trained on open source code should be considered asnew'' or asderivative'' work, with possible implications on license infringements. In this work, we run a large-scale study investigating the extent to which DL models tend to clone code from their training set when recommending code completions. Such an exploratory study can help in assessing the magnitude of the potential licensing issues mentioned before: If these models tend to generate new code that is unseen in the training set, then licensing issues are unlikely to occur. Otherwise, a revision of these licenses urges to regulate how the code generated by these models should be treated when used, for example, in a commercial setting. Highlights from our results show that ~10% to ~0.1% of the predictions generated by a state-of-the-art DL-based code completion tool are Type-1 clones of instances in the training set, depending on the size of the predicted code. Long predictions are unlikely to be cloned.",
        "authors": [
            {
                "name": "Matteo Ciniselli",
                "institution": "Universit\u00e0 della Svizzera Italiana",
                "country": "Switzerland"
            },
            {
                "name": "Luca Pascarella",
                "institution": "Universit\u00e0 della Svizzera italiana (USI)",
                "country": "Switzerland"
            },
            {
                "name": "Gabriele Bavota",
                "institution": "Software Institute, USI Universit\u00e0 della Svizzera italiana",
                "country": "Switzerland"
            }
        ]
    },
    {
        "title": "Replicating Data Pipelines with GrimoireLab",
        "topics": "Hackathon",
        "abstract": "In this paper, we present our MSR Hackathon 2022 project that replicates an existing Gitter study using GrimoireLab. We compare the previous study\u2019s pipeline with our GrimoireLab implementation in terms of speed, data consistency, organization, and the learning curve to get started. We believe our experience with GrimoireLab can help future researchers in making the right choice while implementing their data pipelines over Gitter and Github data.",
        "authors": [
            {
                "name": "Kalvin Eng",
                "institution": "University of Alberta",
                "country": null
            },
            {
                "name": "Hareem Sahar",
                "institution": "University of Alberta",
                "country": null
            }
        ]
    },
    {
        "title": "Empirical Standards for Repository Mining",
        "topics": "Tutorials",
        "abstract": "The purpose of scholarly peer review is to evaluate the quality of scientific manuscripts. However, study after study demonstrates that peer review neither effectively nor reliably assesses research quality. Empirical standards attempt to address this problem by modelling a scientific community\u2019s expectations for each kind of empirical study conducted in that community. This should enhance not only the quality of research but also the reliability and predictability of peer review, as scientists adopt the standards in both their researcher and reviewer roles. However, these improvements depend on the quality and adoption of the standards. This tutorial will therefore present the empirical standard for mining software repositories, both to communicate its contents and to get feedback from the attendees. The tutorial will be organized into three parts: (1) brief overview of the empirical standards project; (2) detailed presentation of the repository mining standard; (3) discussion and suggestions for improvement.",
        "authors": [
            {
                "name": "Paul Ralph",
                "institution": "Dalhousie University",
                "country": "Canada"
            },
            {
                "name": "Tushar Sharma",
                "institution": "Dalhousie University",
                "country": "Canada"
            },
            {
                "name": "Preetha Chatterjee",
                "institution": "Drexel University, USA",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Towards Reliable Agile Iterative Planning via Predicting Documentation Changes of Work Items",
        "topics": "Technical Papers",
        "abstract": "In agile iterative development, an agile team needs to analyze documented information for effort estimation and sprint planning. While documentation can be changed, the documentation changes after sprint planning may invalidate the estimated effort and sprint plan. Hence, to help the team be aware of the potential documentation changes, we developed DocWarn to estimate the probability that a work item will have documentation changes. We developed three variations of DocWarn, which are based on the characteristics extracted from the work items (DocWarn-C), the natural language text (DocWarn-T), and both inputs (DocWarn-H).",
        "authors": [
            {
                "name": "Jirat Pasuksmit",
                "institution": "University of Melbourne",
                "country": "Australia"
            },
            {
                "name": "Patanamon Thongtanunam",
                "institution": "University of Melbourne",
                "country": "Australia"
            },
            {
                "name": "Shanika Karunasekera",
                "institution": "The University of Melbourne",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "Quid Pro Quo: An Exploration of Reciprocity in Code Review",
        "topics": "Hackathon",
        "abstract": "We explore the role of reciprocity in code review processes. Reciprocity manifests itself in two ways: 1) reviewing code for others translates to accepted code contributions, and 2) having contributions accepted increase the reviews made for others. We use vector autoregressive (VAR) models  to explore the causal relation between reviews performed and accepted contributions. After fitting VAR models for 24 active open-source developers, we found evidence of reciprocity in 6 of them. These results suggest reciprocity does play a role in code review, that can potentially be exploited to increase reviewer participation.",
        "authors": [
            {
                "name": "Carlos Gavidia-Calderon",
                "institution": "The Open University",
                "country": "United Kingdom"
            },
            {
                "name": "DongGyun Han",
                "institution": "Singapore Management University",
                "country": "Singapore"
            },
            {
                "name": "Amel Bennaceur",
                "institution": "The Open University",
                "country": "United Kingdom"
            }
        ]
    },
    {
        "title": "Recommending Code Improvements Based on Stack Overflow Answer Edits",
        "topics": "Registered Reports",
        "abstract": "\\textbf{Background:} Sub-optimal code is prevalent in software systems. Developers may write low-quality code due to many reasons, such as lack of technical knowledge, lack of experience, time pressure, management decisions, and even unhappiness. Once sub-optimal code is unknowingly (or knowingly) integrated into the codebase of software systems, its accumulation may lead to large maintenance costs and technical debt. Stack Overflow is a popular website for programmers to ask questions and share their code snippets. The crowdsourced and collaborative nature of Stack Overflow has created a large source of programming knowledge that can be leveraged to assist developers in their day-to-day activities.",
        "authors": [
            {
                "name": "Chaiyong Ragkhitwetsagul",
                "institution": "Mahidol University",
                "country": "Thailand"
            },
            {
                "name": "Matheus Paixao",
                "institution": "University of Fortaleza",
                "country": "Brazil"
            }
        ]
    },
    {
        "title": "Comments on Comments: Where Code Review and Documentation Meet",
        "topics": "Technical Papers",
        "abstract": "An important function of code review is to increase understanding; helping reviewers understand a code change aides in knowledge transfer and finding bugs. Comments in code largely serve a similar purpose, helping future readers understand the program. It is thus natural to study what happens when these two forms of understanding collide. We ask: what documentation-related comments do reviewers make and how do they affect understanding of the contribution? We analyze ca.~700K review comments on 2,000 (Java and Python) GitHub projects, and propose several filters to identify which comments are likely to be either in response to a change in documentation and/or a call for such a change. We identify 65K such cases. We next develop a taxonomy of the reviewer intents behind such \u201ccomments on comments\u201d. We find that achieving a shared understanding of the code is key: reviewer comments most often focused on clarification, followed by pointing out issues to fix, such as typos and outdated comments. Curiously, clarifying comments were frequently suggested (often verbatim) by the reviewer, indicating a desire to persist their understanding acquired during code review. We conclude with a discussion of implications of our comments-on-comments dataset for research on improving code review, including the potential benefits for automating code review.",
        "authors": [
            {
                "name": "Nikitha Rao",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Jason Tsay",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Martin Hirzel",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Vincent J. Hellendoorn",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Using Active Learning to Find High-Fidelity Builds",
        "topics": "Technical Papers",
        "abstract": "Modern software is incredibly complex. A typical application may comprise hundreds or thousands of reusable components. Auto-mated package managers can help to maintain a consistent set of dependency versions, but ultimately the solvers in these systems rely on constraints generated by humans. At scale, small errors add up, and it becomes increasingly difficult to find high-fidelity configurations. We cannot test all configurations, because the space is combinatorial, so exhaustive exploration is infeasible.In this paper, we present Reliabuild, an auto-tuning framework that efficiently explores the build configuration space and learns which package versions are likely to result in a successful configuration. We implement two models in Reliabuild to rank the different configurations and use adaptive sampling to select good configurations with fewer samples. We demonstrate the effectiveness of Reliabuildby evaluating 31,186 build configurations of 61 packages from the Extreme-scale Scientific Software Stack (E4S), and we show that Reliabuild selects good configurations efficiently. For example,Reliabuildselects3\u00d7the number of good configurations in comparison to random sampling for several packages including Abyss, Bolt, libnrm, OpenMPI. Our framework is also able to select all the high fidelity builds in half the number of samples required by random sampling for packages such as Chai, OpenMPI,py-petsc4py, and slepc. We further use the model to learn statistics about the compatibility of different packages, which will enable package solvers to better select high-fidelity build configurations automatically.",
        "authors": [
            {
                "name": "Harshitha Menon",
                "institution": "Lawrence Livermore National Lab",
                "country": null
            },
            {
                "name": "Konstantinos Parasyris",
                "institution": "Lawrence Livermore National Laboratory",
                "country": null
            },
            {
                "name": "Todd Gamblin",
                "institution": "Lawrence Livermore National Laboratory",
                "country": null
            },
            {
                "name": "Tom Scogland",
                "institution": "Lawrence Livermore National Laboratory",
                "country": null
            }
        ]
    },
    {
        "title": "Which bugs are missed in code reviews: An empirical study on SmartSHARK dataset",
        "topics": "Mining Challenge",
        "abstract": "In pull-based development systems, code reviews and pull request comments play important roles in improving code quality. In such systems, reviewers attempt to carefully check a piece of code by different unit tests. Unfortunately, sometimes they miss bugs in their review of pull requests, which lead to quality degradations of the systems. In other words, disastrous consequences occur when bugs are observed after merging the pull requests. The lack of a concrete understanding of these bugs led us to investigate them and categorize them. In this research, we try to identify missed bugs in pull requests of SmartSHARK dataset projects. Our contribution is twofold. First, we hypothesized merged pull requests that have code reviews, code review comments, or pull request comments after merging, may have missed bugs after the code review. We considered these merged pull requests as candidate pull requests having missed bugs. Based on our assumption, we obtained 3,261 candidate pull requests from 77 open-source GitHub projects. After two rounds of restrictive manual analysis, we found 187 bugs missed in 173 pull requests. In the first step, we found 224 buggy pull requests containing missed bugs after merging the pull requests. Secondly, we defined and finalized a taxonomy that is appropriate for the bugs that we found and then found the distribution of bug categories after analyzing those pull requests all over again. The categories of missed bugs in pull requests and their distributions are: semantic (51.34%), build (15.5%), analysis checks (9.09%), compatibility (7.49%), concurrency (4.28%), configuration (4.28%), GUI (2.14%), API (2.14%), security (2.14%), and memory (1.6%).",
        "authors": [
            {
                "name": "fatemeh khoshnoud",
                "institution": "Department of Computer Science and Engineering and IT; School of Electrical and Computer Engineering, Shiraz University",
                "country": "Iran"
            },
            {
                "name": "Ali Rezaei Nasab",
                "institution": "Department of Computer Science and Engineering and IT; School of Electrical and Computer Engineering, Shiraz University",
                "country": "Iran"
            },
            {
                "name": "Zahra Toudeji",
                "institution": "Department of Computer Science and Engineering and IT; School of Electrical and Computer Engineering, Shiraz University",
                "country": "Iran"
            },
            {
                "name": "Ashkan Sami",
                "institution": "Shiraz University",
                "country": "Iran"
            }
        ]
    },
    {
        "title": "SoCCMiner: A Source Code-Comments and Comment-Context Miner",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Numerous tools exist for mining source code and software development process metrics. However, very few publicly available tools focus on source code comments, a crucial software artifact. This paper presents SoCCMiner (Source Code-Comments and Comment-Context Miner), a tool that offers multiple mining pipelines. It is the first readily available (plug-and-play) and customizable open-source tool for mining source code contextual information of comments at different granularities (Class comments, Method comments, Interface comments, and other granular comments). Mining comments at different source code granularities can aid researchers and practitioners working in a host of applications that focus on source code comments, such as Self-Admitted Technical Debt, Program Comprehension, and other applications. Furthermore, it is highly adaptable and extendable to include additional attributes and support other programming languages. This prototype supports the Java programming language.",
        "authors": [
            {
                "name": "Murali Sridharan",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Mika M\u00e4ntyl\u00e4",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Ma\u00eblick Claes",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Leevi Rantala",
                "institution": "University of Oulu",
                "country": "Finland"
            }
        ]
    },
    {
        "title": "SOSum: A Dataset of Stack Overflow Post Summaries",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Stack Overflow (SO) is becoming an indispensable part of the modern software development workflow. However, navigating SO posts and comparing different solutions is time-consuming and cumbersome given the limited time, attention, and memory capacity of programmers. Recent research has proposed to summarize SO posts to concise text to help programmers quickly decide the relevance and quality of SO posts. Yet there is no large, comprehensive dataset of high-quality SO post summaries, which hinders the development and evaluation of post summarization techniques. We present SOSum, a dataset of 2278 popular SO posts with manually labeled summative sentences. Questions in SOSum cover 669 tags with a median view count of 253K and a median post score of 17. This dataset will foster research on sentence-level summarization of SO posts and has the potential to facilitate text summarization research on other types of textual software artifacts such as programming tutorials.",
        "authors": [
            {
                "name": "Bonan Kou",
                "institution": "Purdue University",
                "country": "United States"
            },
            {
                "name": "Yifeng Di",
                "institution": "Purdue University",
                "country": "United States"
            },
            {
                "name": "Muhao Chen",
                "institution": "University of Southern California",
                "country": "United States"
            },
            {
                "name": "Tianyi Zhang",
                "institution": "Purdue University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Investigating the Impact of Forgetting in Software Development",
        "topics": "Registered Reports",
        "abstract": "Context: Forgetting is defined as a gradual process of losing information. Even though there are many studies demonstrating the effect of forgetting in software development, to the best of our knowledge, no study explores the impact of forgetting in software development using a controlled experiment approach. Objective: We would like to provide insights on the impact of forgetting in software development projects. We want to examine whether the recency & frequency of interaction impact forgetting in software development. Methods: We will conduct an experiment that examines the impact of forgetting in software development. Participants will first do an initial task. According to their initial task performance, they will be assigned to either the experiment or the control group. The experiment group will then do two additional tasks to enhance their exposure to the code. Both groups will then do a final task to see if additional exposure to the code benefits the experiment group\u2019s performance in the final task.  Finally, we will conduct a survey and a recall task with the same participants to collect data about their perceptions of forgetting and quantify their memory performance, respectively",
        "authors": [
            {
                "name": "Utku Unal",
                "institution": "METU",
                "country": null
            },
            {
                "name": "Eray T\u00fcz\u00fcn",
                "institution": "Bilkent University",
                "country": "Turkey"
            },
            {
                "name": "Tamer Gezici",
                "institution": "Bilkent University",
                "country": null
            },
            {
                "name": "Ausaf Ahmed Farooqui",
                "institution": "Bilkent University",
                "country": null
            }
        ]
    },
    {
        "title": "An Exploratory Study on Refactoring Documentation in Issues Handling",
        "topics": "Mining Challenge",
        "abstract": "Understanding the practice of refactoring documentation is of paramount importance in academia and industry. Issue tracking systems are used by most software projects enabling developers, quality assurance, managers, and users to submit feature requests and other tasks such as bug fixing and code review. Although recent studies explored how to document refactoring in commit messages, little is known about how developers describe their refactoring needs in issues. In this study, we aim at exploring developer-reported refactoring changes in issues to better understand what developers consider to be problematic in their code and how they handle it. Our approach relies on text mining 45,477 refactoring-related issues and identifying refactoring patterns from a diverse corpus of 77 Java projects by investigating issues associated with 15,833 refactoring operations and developers\u2019 explicit refactoring intention. Our results show that (1) developers mostly use move refactoring related terms/phrases to target refactoring related issues; and (2) developers tend to explicitly mention the improvement of specific quality attributes and focus on duplicate code removal. We envision our findings enabling tool builders to support developers with automated documentation of refactoring changes in issues.",
        "authors": [
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Anthony Peruma",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Christian D. Newman",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Smelly Variables in Ansible Infrastructure Code: Detection, Prevalence, and Lifetime",
        "topics": "Technical Papers",
        "abstract": "Infrastructure as Code is the practice of automating the provisioning, configuration, and orchestration of network nodes using code in which variable values such as configuration parameters, node hostnames, etc. play a central role. Mistakes in these values are an important cause of infrastructure defects and corresponding outages. Ansible, a popular IaC language, nonetheless features semantics which can cause confusion about the value of variables.",
        "authors": [
            {
                "name": "Ruben Opdebeeck",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            },
            {
                "name": "Ahmed Zerouali",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            },
            {
                "name": "Coen De Roover",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            }
        ]
    },
    {
        "title": "npm-filter: Automating the mining of dynamic information from npm packages",
        "topics": "Data and Tool Showcase Track",
        "abstract": "The static properties of code repositories, e.g., lines of code, dependents, dependencies, etc. can be readily scraped from code hosting platforms such as GitHub, and from package management systems such as npm for JavaScript; Although no less important, information related to the \\textit{dynamic} properties of programs, e.g., number of tests in a test suite that pass or fail, is less readily available. The ability to easily collect this dynamic information could be immensely useful to researchers conducting corpus analyses, as they could differentiate projects based on properties that can only be observed by running them.",
        "authors": [
            {
                "name": "Ellen Arteca",
                "institution": "Northeastern University",
                "country": "United States"
            },
            {
                "name": "Alexi Turcotte",
                "institution": "Northeastern University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "On the Naturalness of Fuzzer Generated Code",
        "topics": "Technical Papers",
        "abstract": "Compiler fuzzing tools such as Csmith have uncovered many bugs in compilers by randomly sampling programs from a generative model. The success of these tools is often attributed to their ability to generate unexpected corner case inputs that developers tend to overlook during manual testing. At the same time, their chaotic nature makes fuzzer-generated test cases notoriously hard to interpret, which has lead to the creation of input simplification tools such as C-Reduce (for C compiler bugs). In until now unrelated work, researchers have also shown that human-written software tends to be rather repetitive and predictable to language models. Studies show that developers deliberately write more predictable code, whereas code with bugs is relatively unpredictable. In this study, we ask the natural questions of whether this high predictability property of code also, and perhaps counter-intuitively,  applies to fuzzer-generated code. That is, we investigate whether fuzzer-generated compiler inputs are deemed unpredictable by a language model built on human-written code and surprisingly conclude that \\emph{it is not}. To the contrary, Csmith fuzzer-generated programs are \\emph{more} predictable on a per-token basis than human-written C programs. Furthermore, bug-triggering tended to be more predictable still than random inputs, and the C-Reduce minimization tool did not substantially increase this predictability. Rather, we find that bug-triggering inputs are unpredictable relative to \\emph{Csmith\u2019s own} generative model. This is encouraging; our results suggest promising research directions on incorporating predictability metrics in the fuzzing and reduction tools themselves.",
        "authors": [
            {
                "name": "Rajeswari Hita Kambhamettu",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "John Billos",
                "institution": "Wake Forest University",
                "country": "United States"
            },
            {
                "name": "Carolyn \"Tomi\" Oluwaseun-Apo",
                "institution": "Pennsylvania State University",
                "country": "United States"
            },
            {
                "name": "Benjamin Gafford",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Rohan Padhye",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Vincent J. Hellendoorn",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems",
        "topics": "Technical Papers",
        "abstract": "Software projects use Issue Tracking Systems (ITS) like JIRA to track issues and organize the workflows around them. Issues are often inter-connected via different links such as the default JIRA link types Duplicate, Relate, Block, and Subtask. While previous research has focused on analyzing and predicting duplication links, this work aims at understanding the various other link types, their prevalence, and characteristics towards a more reliable link type prediction.",
        "authors": [
            {
                "name": "Clara Marie L\u00fcders",
                "institution": "University of Hamburg",
                "country": "Germany"
            },
            {
                "name": "Abir Bouraffa",
                "institution": "University of Hamburg",
                "country": "Germany"
            },
            {
                "name": "Walid Maalej",
                "institution": "University of Hamburg",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "ApacheJIT: A Large Dataset for Just-In-Time Defect Prediction",
        "topics": "Data and Tool Showcase Track",
        "abstract": "In this paper, we present ApacheJIT, a large dataset for Just-In-Time defect prediction. ApacheJIT consists of clean and bug-inducing software changes in popular Apache projects. ApacheJIT has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). Having a large number of commits makes ApacheJIT a suitable dataset for machine learning models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data.",
        "authors": [
            {
                "name": "Hossein Keshavarz",
                "institution": "David R. Cheriton School of Computer Science, University of Waterloo",
                "country": "Canada"
            },
            {
                "name": "Mei Nagappan",
                "institution": "University of Waterloo",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "SOSum: A Dataset of Stack Overflow Post Summaries",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Stack Overflow (SO) is becoming an indispensable part of the modern software development workflow. However, navigating SO posts and comparing different solutions is time-consuming and cumbersome given the limited time, attention, and memory capacity of programmers. Recent research has proposed to summarize SO posts to concise text to help programmers quickly decide the relevance and quality of SO posts. Yet there is no large, comprehensive dataset of high-quality SO post summaries, which hinders the development and evaluation of post summarization techniques. We present SOSum, a dataset of 2278 popular SO posts with manually labeled summative sentences. Questions in SOSum cover 669 tags with a median view count of 253K and a median post score of 17. This dataset will foster research on sentence-level summarization of SO posts and has the potential to facilitate text summarization research on other types of textual software artifacts such as programming tutorials.",
        "authors": [
            {
                "name": "Bonan Kou",
                "institution": "Purdue University",
                "country": "United States"
            },
            {
                "name": "Yifeng Di",
                "institution": "Purdue University",
                "country": "United States"
            },
            {
                "name": "Muhao Chen",
                "institution": "University of Southern California",
                "country": "United States"
            },
            {
                "name": "Tianyi Zhang",
                "institution": "Purdue University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Code Review Practices for Refactoring Changes: An Empirical Study on OpenStack",
        "topics": "Technical Papers",
        "abstract": "Modern code review is a widely used technique employed in both industrial and open-source projects to improve software quality, share knowledge, and ensure adherence to coding standards and guidelines. During code review, developers may discuss refactoring activities before merging code changes in the codebase. To date, code review has been extensively studied to explore its general challenges, best practices and outcomes, and socio-technical aspects. However, little is known about how refactoring is being reviewed and what developers care about when they review refactored code. Hence, in this work, we present a quantitative and qualitative study to understand what are the main criteria developers rely on to develop a decision about accepting or rejecting a submitted refactored code, and what makes this process challenging. Through a case study of 11,010 refactoring and non-refactoring reviews spread across OpenStack open-source projects, we find that refactoring-related code reviews take significantly longer to be resolved in terms of code review efforts. Moreover, upon performing a thematic analysis on a significant sample of the refactoring code review discussions, we built a comprehensive taxonomy consisting of 28 refactoring review criteria in the context of MCR. We envision our findings reaffirming the necessity of developing accurate and efficient tools and techniques that can assist developers in the review process in the presence of refactorings.",
        "authors": [
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Moataz Chouchen",
                "institution": "ETS",
                "country": "Canada"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Geographic Diversity in Public Code Contributions",
        "topics": "Technical Papers",
        "abstract": "We conduct an exploratory, large-scale, longitudinal study of 50 years of commits to publicly available version control system repositories, in order to characterize the geographic diversity of contributors to public code and its evolution over time. We analyze in total 2.2 billion commits collected by Software Heritage from 160 million projects and authored by 43 million authors during the 1971-2021 time period. We geolocate developers to 12 world regions derived from the United Nation geoscheme, using as signals email top-level domains, author names compared with names distributions around the world, and UTC offsets mined from commit metadata. We find evidence of the early dominance of North America in open source software, later joined by Europe. After that period, the geographic diversity in public code has been constantly increasing. We also identify relevant historical shifts related to the UNIX wars, the increase of coding literacy in Central and South Asia, and broader phenomena like colonialism and people movement across countries (immigration/emigration).",
        "authors": [
            {
                "name": "Davide Rossi",
                "institution": "University of Bologna",
                "country": null
            },
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "Senatus: A Fast and Accurate Code-to-Code Recommendation Engine",
        "topics": "Technical Papers",
        "abstract": "Machine learning on source code (MLOnCode) is a popular research field that has been driven by the availability of large-scale code repositories and the development of powerful probabilistic and deep learning models for mining source code. Code-to-code recommendation is a task in MLOnCode that aims to recommend relevant, diverse and concise code snippets that usefully extend the code currently being written by a developer in their development environment (IDE). Code-to-code recommendation engines hold the promise of increasing developer productivity by reducing context switching from the IDE and increasing code-reuse. Existing code-to-code recommendation engines do not scale gracefully to large codebases, exhibiting a linear growth in query time as the code repository increases in size. In addition, existing code-to-code recommendation engines fail to account for the global statistics of code repositories in the ranking function, such as the distribution of code snippet lengths, leading to sub-optimal retrieval results. We address both of these weaknesses with \\emph{Senatus}, a new code-to-code recommendation engine. At the core of Senatus is \\emph{De-Skew} LSH a new locality sensitive hashing (LSH) algorithm that indexes the data for fast (sub-linear time) retrieval while also counteracting the skewness in the snippet length distribution using novel abstract syntax tree-based feature scoring and selection algorithms. We evaluate Senatus and find the recommendations to be of higher quality than competing baselines, while achieving faster search. For example on the CodeSearchNet dataset Senatus improves performance by 31.21% F1 and  147.9\\emph{x} faster query time compared to Facebook Aroma. Senatus also outperforms standard MinHash LSH by 29.2% F1 and 51.02\\emph{x} faster query time.",
        "authors": [
            {
                "name": "Fran Silavong",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Sean Moran",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Antonios Georgiadis",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Rohan Saphal",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            },
            {
                "name": "Robert Otter",
                "institution": "JP Morgan Chase & Co.",
                "country": null
            }
        ]
    },
    {
        "title": "The General Index of Software Engineering Papers",
        "topics": "Data and Tool Showcase Track",
        "abstract": "We introduce the General Index of Software Engineering Papers, a dataset of fulltext-indexed papers from the most prominent scientific venues in the field of Software Engineering. The dataset includes both complete bibliographic information and indexed n-grams (sequence of contiguous words after removal of stopwords and non-words, for a total of 577\u2019276\u2019382 unique n-grams in this release) with length 1 to 5 for 44\u2019581 papers retrieved from 34 venues over the 1971\u20132020 period. The dataset serves use cases in the field of meta-research, allowing to introspect the output of software engineering research even when access to papers or scholarly search engines is not possible (e.g., due to contractual reasons). The dataset also contributes to making such analyses reproducible and independently verifiable, as opposed to what happens when they are conducted using 3rd-party and non-open scholarly indexing services. The dataset is available as a portable Postgres database dump and released as open data.",
        "authors": [
            {
                "name": "Zeinab Abou Khalil",
                "institution": "Inria",
                "country": null
            },
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "SLNET: A Redistributable Corpus of 3rd-party Simulink Models",
        "topics": "Data and Tool Showcase Track",
        "abstract": "MATLAB/Simulink is widely used for model-based design. Engineers create Simulink models and compile them to embedded code, often to control safety-critical cyber-physical systems in automotive, aerospace, and healthcare applications. Despite Simulink\u2019s importance, there are few large-scale empirical Simulink studies, perhaps because there is no large readily available corpus of third-party open-source Simulink models. To enable empirical Simulink studies, this paper introduces SLNET, the largest corpus of freely available third-party Simulink models. SLNET has several advantages over earlier collections. Specifically, SLNET is 8 times larger than the largest previous corpus of Simulink models, includes fine-grained metadata, is constructed automatically, is self-contained, and allows redistribution. SLNET is available under permissive open-source licenses and contains all of its collection and analysis tools.",
        "authors": [
            {
                "name": "Sohil Lal Shrestha",
                "institution": "The University of Texas at Arlington",
                "country": "United States"
            },
            {
                "name": "Shafiul Azam Chowdhury",
                "institution": "University of Texas at Arlington",
                "country": "United States"
            },
            {
                "name": "Christoph Csallner",
                "institution": "University of Texas at Arlington",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Studying the Impact of Continuous Delivery Adoption on Bug-Fixing Time in Apache\u2019s Open-Source Projects",
        "topics": "Mining Challenge",
        "abstract": "Buggy software impacts people\u2019s lives and businesses. Nowadays, a huge portion of a software project\u2019s cost is spent on debugging (finding and fixing bugs). Therefore, reducing the time needed to release new software versions free from bugs becomes crucial. Continuous delivery (CD) arises as an alternative to traditional software release engineering by providing the capability to faster and continuously release software to customers through automated pipelines. Previous studies claim that CD adoption leads to a reduction in the software release cycle time, including the time lag to fix reported bugs (bug-fixing time) and apply correction patches in the affected versions. However, there is a lack of empirical evidence supporting (or not) this claim. To fulfill this gap, we conducted an empirical study to evaluate the impact of CD adoption in the bug-fixing time. We study 25 open-source projects comparing the bug-fixing time before and after adopting CD. Our results show that bug-fixing time after CD adoption becomes shorter (with statistical significance) than the bug-fixing time before CD adoption.",
        "authors": [
            {
                "name": "Carlos Diego Andrade de Almeida",
                "institution": "Federal University of Cear\u00e1",
                "country": "Brazil"
            },
            {
                "name": "Diego N. Feij\u00f3",
                "institution": "Federal University of Cear\u00e1",
                "country": "Brazil"
            },
            {
                "name": "Lincoln Souza Rocha",
                "institution": "Federal University of Cear\u00e1",
                "country": "Brazil"
            }
        ]
    },
    {
        "title": "Challenges in Migrating Imperative Deep Learning Programs to Graph Execution: An Empirical Study",
        "topics": "Technical Papers",
        "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code that supports symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce DL code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. While hybrid approaches aim for the \u201cbest of both worlds,\u201d the challenges in applying them in the real world are largely unknown. We conduct a data-driven analysis of challenges\u2014and resultant bugs\u2014involved in writing reliable yet performant imperative DL code by studying 250 open-source projects, consisting of 19.7 MLOC, along with 470 and 446 manually examined code patches and bug reports, respectively. The results indicate that hybridization: (i) is prone to API misuse, (ii) can result in performance degradation\u2014the opposite of its intention, and (iii) has limited application due to execution mode incompatibility. We put forth several recommendations, best practices, and anti-patterns for effectively hybridizing imperative DL code, potentially benefiting DL practitioners, API designers, tool developers, and educators.",
        "authors": [
            {
                "name": "Tatiana Castro V\u00e9lez",
                "institution": "City University of New York (CUNY) Graduate Center",
                "country": "United States"
            },
            {
                "name": "Raffi Khatchadourian",
                "institution": "City University of New York (CUNY) Hunter College",
                "country": "United States"
            },
            {
                "name": "Mehdi Bagherzadeh",
                "institution": "Oakland University",
                "country": "United States"
            },
            {
                "name": "Anita Raja",
                "institution": "City University of New York (CUNY) Hunter College",
                "country": "United States"
            }
        ]
    },
    {
        "title": "How to Improve Deep Learning for Software Analytics (a case study with code smell detection)",
        "topics": "Technical Papers",
        "abstract": "To reduce technical debt and make code more maintainable, it is important to be able to warn   programmers about code smells. State-of-the-art code small detectors use deep learners, without much exploration of alternatives within that technology.",
        "authors": [
            {
                "name": "Rahul Yedida",
                "institution": null,
                "country": null
            },
            {
                "name": "Tim Menzies",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Starting the InnerSource Journey: Key Goals and Metrics to Measure Collaboration",
        "topics": "Industry Track",
        "abstract": "InnerSource is the application of best open source practices within the walls of the organization. Large corporations are required to be more and more efficient in the development of software and even more in the banking industry. There are three main areas of expenditure: infrastructure and facilities, people, and technology. The latter is of importance nowadays as key for the business and core to this paper. Reusability and collaboration are some of the ways a large corporation can be more efficient in technology. By being able to discover existing software and collaborating across business units, departments, or even geographical regions, corporations can share effort across them, and avoid starting once and again a similar piece of software.",
        "authors": [
            {
                "name": "Daniel Izquierdo-Cortazar",
                "institution": "Bitergia",
                "country": "Spain"
            },
            {
                "name": "Jes\u00fas Alonso-Guti\u00e9rrez",
                "institution": "Santander Bank",
                "country": "Spain"
            },
            {
                "name": "Alberto P\u00e9rez Garc\u00eda-Plaza",
                "institution": "Bitergia",
                "country": "Spain"
            },
            {
                "name": "Gregorio Robles",
                "institution": "Universidad Rey Juan Carlos",
                "country": "Spain"
            },
            {
                "name": "Jesus M. Gonzalez-Barahona",
                "institution": "Universidad Rey Juan Carlos",
                "country": "Spain"
            }
        ]
    },
    {
        "title": "Dazzle: Using Optimized Generative Adversarial Networks to Address Security Data Class Imbalance Issue",
        "topics": "Technical Papers",
        "abstract": "Background: Machine learning techniques have been widely used and demonstrate promising performance in many software security tasks such as software vulnerability prediction. However, the class ratio within software vulnerability datasets is often highly imbalanced (since the percentage of observed vulnerability is usually very low). Goal: To help security practitioners address software security data class imbalanced issues and further help build better prediction models with resampled datasets. Method: We introduce an approach called Dazzle which is an optimized version of conditional Wasserstein Generative Adversarial Networks with gradient penalty (cWGAN-GP). Dazzle explores the architecture hyperparameters of cWGAN-GP with a novel optimizer called Bayesian Optimization. We use Dazzle to generate minority class samples to resample the original imbalanced training dataset. Results: We evaluate Dazzle with three software security datasets, i.e., Moodle vulnerable files, Ambari bug reports, and JavaScript function code. We show that Dazzle is practical to use and demonstrates promising improvement over existing state-of-the-art oversampling techniques such as SMOTE (e.g., with an average of about 60% improvement rate over SMOTE in recall among all datasets). Conclusion: Based on this study, we would suggest the use of optimized GANs as an alternative method for security vulnerability data class imbalanced issues.",
        "authors": [
            {
                "name": "Rui Shu",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tianpei Xia",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Laurie Williams",
                "institution": "North Carolina State University",
                "country": "United States"
            },
            {
                "name": "Tim Menzies",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "CamBench - Cryptographic API Misuse Detection Tool Benchmark Suite",
        "topics": "Registered Reports",
        "abstract": "Context: Cryptographic APIs are often misused in real-world applications. Therefore, many cryptographic API misuse detection tools have been introduced. However, there exists no established reference benchmark for a fair and comprehensive comparison and evaluation of these tools. While there are benchmarks, they often only address a subset of the domain or were only used to evaluate a subset of existing misuse detection tools. Objective: To fairly compare cryptographic API misuse detection tools and to drive future development in this domain, we will devise such a benchmark. Openness and transparency in the generation process are key factors to fairly generate and establish the needed benchmark. Method:We propose an approach where we derive the benchmark generation methodology from the literature which consists of general best practices in benchmarking and domain-specific benchmark generation. A part of this methodology is transparency and openness of the generation process, which is achieved by pre-registering this work. Based on our methodology we design CamBench, a fair \u201cCryptographic API Misuse Detection Tool Benchmark Suite\u201d. We will implement the first version of CamBench limiting the domain to Java, the JCA, and static analyses. Finally, we will use CamBench to compare current misuse detection tools and compare CamBench to related benchmarks of its domain.",
        "authors": [
            {
                "name": "Michael Schlichtig",
                "institution": "Heinz Nixdorf Institute at Paderborn University",
                "country": "Germany"
            },
            {
                "name": "Anna-Katharina Wickert",
                "institution": "TU Darmstadt",
                "country": "Germany"
            },
            {
                "name": "Stefan Kr\u00fcger",
                "institution": "Independent Researcher",
                "country": "Germany"
            },
            {
                "name": "Eric Bodden",
                "institution": "University of Paderborn; Fraunhofer IEM",
                "country": "Germany"
            },
            {
                "name": "Mira Mezini",
                "institution": "TU Darmstadt",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "SLNET: A Redistributable Corpus of 3rd-party Simulink Models",
        "topics": "Data and Tool Showcase Track",
        "abstract": "MATLAB/Simulink is widely used for model-based design. Engineers create Simulink models and compile them to embedded code, often to control safety-critical cyber-physical systems in automotive, aerospace, and healthcare applications. Despite Simulink\u2019s importance, there are few large-scale empirical Simulink studies, perhaps because there is no large readily available corpus of third-party open-source Simulink models. To enable empirical Simulink studies, this paper introduces SLNET, the largest corpus of freely available third-party Simulink models. SLNET has several advantages over earlier collections. Specifically, SLNET is 8 times larger than the largest previous corpus of Simulink models, includes fine-grained metadata, is constructed automatically, is self-contained, and allows redistribution. SLNET is available under permissive open-source licenses and contains all of its collection and analysis tools.",
        "authors": [
            {
                "name": "Sohil Lal Shrestha",
                "institution": "The University of Texas at Arlington",
                "country": "United States"
            },
            {
                "name": "Shafiul Azam Chowdhury",
                "institution": "University of Texas at Arlington",
                "country": "United States"
            },
            {
                "name": "Christoph Csallner",
                "institution": "University of Texas at Arlington",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Between JIRA and GitHub: ASFBot and its Influence on Human Comments in Issue Trackers",
        "topics": "Mining Challenge",
        "abstract": "In recent years many Open-Source Software (OSS) projects have adopted various automations to automate repetitive tasks, one category of automations adopted by OSS are so-called bots. In previous work, researchers have found that the adoption of bots helps open-source developers merge more pull requests and reduces the need for communication between developers. The Apache Software Foundation (ASF) is a foundation that provides open-source software, and it supports the OSS projects that are a member of it. Projects that are a part of the ASF can choose to adopt the ASFBot, this bot automatically creates links between the JIRA issue tracker and pull requests (PRs) on GitHub. In this exploratory case study, we zoom in on the ASF ecosystem, and we seek to understand how the adoption of one specific bot (the ASFBot) impacts the discussions in the issue-trackers of these projects. In this study, we use the SmartShark dataset to investigate whether the ASFBot affects (i)human comments mentioning pull requests (PRs) and fixes in issue comments and (ii) the general human comment rate on issues. We apply a regression discontinuity design (RDD) on nine projects that are members of the ASF and which have been active both before and after the adoption of the ASFBot. Our results indicate (i) a decrease in comments mentioning pull requests and fixes after the bot adoption and (ii) no effect in the number of human comments after the bot adoption. By taking a first step towards understanding how the adoption of ASFBot impacts the issue tracker of projects we can better understand the advantages that the infrastructure of a foundation like ASF provides, and how it affects the commenting behavior of developers in the issue-tracker.",
        "authors": [
            {
                "name": "Ambarish Moharil",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Dmitrii Orlov",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Samar Jameel",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Tristan Trouwen",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Nathan Cassee",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Alexander Serebrenik",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "An Exploratory Study on Refactoring Documentation in Issues Handling",
        "topics": "Mining Challenge",
        "abstract": "Understanding the practice of refactoring documentation is of paramount importance in academia and industry. Issue tracking systems are used by most software projects enabling developers, quality assurance, managers, and users to submit feature requests and other tasks such as bug fixing and code review. Although recent studies explored how to document refactoring in commit messages, little is known about how developers describe their refactoring needs in issues. In this study, we aim at exploring developer-reported refactoring changes in issues to better understand what developers consider to be problematic in their code and how they handle it. Our approach relies on text mining 45,477 refactoring-related issues and identifying refactoring patterns from a diverse corpus of 77 Java projects by investigating issues associated with 15,833 refactoring operations and developers\u2019 explicit refactoring intention. Our results show that (1) developers mostly use move refactoring related terms/phrases to target refactoring related issues; and (2) developers tend to explicitly mention the improvement of specific quality attributes and focus on duplicate code removal. We envision our findings enabling tool builders to support developers with automated documentation of refactoring changes in issues.",
        "authors": [
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Anthony Peruma",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Christian D. Newman",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "Painting the Landscape of Automotive Software in GitHub",
        "topics": "Technical Papers",
        "abstract": "The automotive industry has transitioned from being electro-mechanical to a software-intensive industry. A current high-end production vehicle contains 100 million+ lines of code surpassing  modern airplanes, the Large Hadron Collider, the Android OS, and Facebook\u2019s front-end software, in code size by a huge margin. Today, software companies worldwide, including Apple, Google, Huawei, Baidu, and Sony are reportedly working to bring their vehicles to the road. This paper ventures into the automotive software landscape in open source, providing a first glimpse into this multi-disciplinary industry with a long history of closed source development. We  paint the landscape of automotive software on GitHub by describing their characteristics and development styles.",
        "authors": [
            {
                "name": "Sangeeth Kochanthara",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Yanja Dajsuren",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Loek Cleophas",
                "institution": "Eindhoven University of Technology (TU/e) and Stellenbosch University (SU)",
                "country": "Netherlands"
            },
            {
                "name": "Mark van den Brand",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "ReCover: a Curated Dataset for Regression Testing Research",
        "topics": "Data and Tool Showcase Track",
        "abstract": "It is recognized in the literature that finding representative data to conduct regression testing research is non-trivial. In our experience within this field, existing datasets are often affected by issues that limit their applicability. Indeed, these datasets often lack fine-grained coverage information, reference software repositories that are not available anymore, or do not allow researchers to readily build and run the software projects, e.g., to obtain additional information. As a step towards better replicability and data-availability in regression testing research, we introduce ReCover, a dataset of 114 pairs of subsequent versions from 28 open source Java projects from GitHub. In particular, ReCover is intended as a consolidation and enrichment of recent dedicated regression testing datasets proposed in the literature, to overcome some of the above described issues, and to make them ready to use with a broader number of regression testing techniques. To this end, we developed a custom mining tool, that we make available as well, to automatically process two recent, massive regression testing datasets, retaining pairs of software versions for which we were able to (1) retrieve the full source code;  (2) build the software in a general-purpose Java/Maven environment (which we provide as a Docker container for ease of replication); and (3) compute fine-grained test coverage metrics. ReCover can be readily employed in regression testing studies, as it bundles in a single package full, buildable source code and detailed coverage reports for all the projects. We envision that its use could foster regression testing research, improving replicability and long-term data availability.",
        "authors": [
            {
                "name": "Francesco Altiero",
                "institution": "Universit\u00e0 degli Studi di Napoli Federico II",
                "country": "Italy"
            },
            {
                "name": "Anna Corazza",
                "institution": "Universit\u00e0 degli Studi di Napoli Federico II",
                "country": "Italy"
            },
            {
                "name": "Sergio Di Martino",
                "institution": "Universit\u00e0 degli Studi di Napoli Federico II",
                "country": "Italy"
            },
            {
                "name": "Adriano Peron",
                "institution": "Universit\u00e0 degli Studi di Napoli Federico II",
                "country": "Italy"
            },
            {
                "name": "Luigi Libero Lucio Starace",
                "institution": "Universit\u00e0 degli Studi di Napoli Federico II",
                "country": "Italy"
            }
        ]
    },
    {
        "title": "Mining the Usage of Reactive Programming APIs: A Study on GitHub and Stack Overflow",
        "topics": "Technical Papers",
        "abstract": "Conventionally, callbacks and inversion of control have been the main tools to structure event-driven applications. Sadly, those patterns constitute a well-known source of design problems. The Reactive Programming (RP) paradigm has arisen as an approach to mitigate these problems. Yet, little evidence has been provided regarding the advantages of RP, and concerns have also arisen about the API usability of RP libraries given their disparate number of operators. In this work, we conduct a study on GitHub (GH) and Stack Overflow (SO) and explore three Reactive Extensions (Rx) libraries (RxJava, RxJS, and RxSwift) with the most GH projects to understand how much the vast Rx operators are being used. Also, we examine Rx SO posts to complement the results from the GH exploration by understanding the problems faced by RP developers and how they relate with the operators\u2019 frequencies found in open source projects. Results reveal that, in spite of its API size, the great majority of the Rx operators are actually being used (95.2%), with only a few, mostly related to RxJava, not being utilized. Also, we unveil 23 topics from SO with more posts concerning the Stream Abstraction (36.4%). Posts related to Dependency Management, Introductory Questions, and iOS Development figure as relevant topics to the community. The findings herein present can not only stimulate advancements in the field by understanding the usage of RP API and the main problems faced by developers, but also help newcomers in identifying the most important operators and the areas that are the most likely to be relevant for a RP application.",
        "authors": [
            {
                "name": "Carlos Zimmerle",
                "institution": "Federal University of Pernambuco",
                "country": "Brazil"
            },
            {
                "name": "Kiev Gama",
                "institution": "Federal University of Pernambuco",
                "country": "Brazil"
            },
            {
                "name": "Fernando Castor",
                "institution": "Utrecht University & Federal University of Pernambuco",
                "country": "Netherlands"
            },
            {
                "name": "Jos\u00e9 Murilo Filho",
                "institution": "Federal University of Pernambuco",
                "country": "Brazil"
            }
        ]
    },
    {
        "title": "Real-World Clone-Detection in Go",
        "topics": "Industry Track",
        "abstract": "In the early stage of development, developers copied internal code snippets to enhance developing efficiency. With the rapid growth of Bytedance, similar or equivalent code snippets across different repositories or different product lines\u2019 codebases would potentially increase the cost of maintenance and distribute vulnerable code snippets. With the application of Clone-Detection, there are multi- ple well-established tools or techniques used for detecting similar code snippets in Java, JavaScript, Objective C and etc. We could hardly find similar tools available for Go, a widely-used program- ming language in the field of server development, especially at Bytedance. For the lack of public and labeled datasets, we utilized a great number of code snippets in Bytedance\u2019s codebase and trained an unsupervised model to propose GoCopyCatch (GoCC), a tool and technique for Clone-Detection in Go.",
        "authors": [
            {
                "name": "Qinyun Wu",
                "institution": "Bytedance Ltd.",
                "country": null
            },
            {
                "name": "Huan Song",
                "institution": "Bytedance Ltd.",
                "country": null
            },
            {
                "name": "Ping Yang",
                "institution": "Bytedance Network Technology",
                "country": null
            }
        ]
    },
    {
        "title": "TSSB-3M: Mining single statement bugs at massive scale",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Single statement bugs are one of the most important ingredients in the evaluation of modern bug detection and automatic program repair methods. By affecting only a single statement, single statement bugs represent a type of bug often overlooked by developers, while still being small enough to be detected and fixed by automatic methods.",
        "authors": [
            {
                "name": "Cedric Richter",
                "institution": "Carl von Ossietzky Universit\u00e4t Oldenburg / University of Oldenburg",
                "country": "Germany"
            },
            {
                "name": "Heike Wehrheim",
                "institution": "Carl von Ossietzky Universit\u00e4t Oldenburg / University of Oldenburg",
                "country": "Germany"
            }
        ]
    },
    {
        "title": "Does This Apply to Me? An Empirical Study of Technical Context in Stack Overflow",
        "topics": "Technical Papers",
        "abstract": "Stack Overflow has become an essential technical resource for developers. However, given the vast amount of knowledge available on Stack Overflow, finding the right information that is relevant for a given task is still challenging, especially when a developer is looking for a solution that applies to their specific requirements or technology stack. Clearly marking answers with their \\textit{context}, i.e., the information that characterizes the technologies and assumptions needed for this answer, is potentially one way to improve navigation. However, there is no information about how often such context is mentioned, and what kind of information it might offer. In this paper, we conduct an empirical study to understand the occurrence of technical context in Stack Overflow answers and comments, using tags as a proxy for technical context. We specifically focus on \\textit{additional context}, where answers/comments mention information that is not already discussed in the question. Our results show that nearly half of our studied threads contain at least one additional context. We find that almost 50% of the additional context are either a library/framework, a programming language, a tool/application, an API, or a database. We also find that answer votes alone are not a good indicator of the presence of additional context in an answer, which suggests that further visual cues to aid navigation may be needed. Overall, our findings show the promise of using additional context as navigational cues.",
        "authors": [
            {
                "name": "Akalanka Galappaththi",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Sarah Nadi",
                "institution": "University of Alberta",
                "country": "Canada"
            },
            {
                "name": "Christoph Treude",
                "institution": "University of Melbourne",
                "country": "Australia"
            }
        ]
    },
    {
        "title": "How to Improve Deep Learning for Software Analytics (a case study with code smell detection)",
        "topics": "Technical Papers",
        "abstract": "To reduce technical debt and make code more maintainable, it is important to be able to warn   programmers about code smells. State-of-the-art code small detectors use deep learners, without much exploration of alternatives within that technology.",
        "authors": [
            {
                "name": "Rahul Yedida",
                "institution": null,
                "country": null
            },
            {
                "name": "Tim Menzies",
                "institution": "North Carolina State University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Smelly Variables in Ansible Infrastructure Code: Detection, Prevalence, and Lifetime",
        "topics": "Technical Papers",
        "abstract": "Infrastructure as Code is the practice of automating the provisioning, configuration, and orchestration of network nodes using code in which variable values such as configuration parameters, node hostnames, etc. play a central role. Mistakes in these values are an important cause of infrastructure defects and corresponding outages. Ansible, a popular IaC language, nonetheless features semantics which can cause confusion about the value of variables.",
        "authors": [
            {
                "name": "Ruben Opdebeeck",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            },
            {
                "name": "Ahmed Zerouali",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            },
            {
                "name": "Coen De Roover",
                "institution": "Vrije Universiteit Brussel",
                "country": "Belgium"
            }
        ]
    },
    {
        "title": "Dataset: Dependency Networks of Open Source Libraries Available Through CocoaPods, Carthage and Swift PM",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Third party libraries are used to integrate existing solutions for common problems and help speed up development. The use of third party libraries, however, can carry risks, for example through vulnerabilities in these libraries. Studying the dependency networks of package managers lets us better understand and mitigate these risks. So far, the dependency networks of the three most important package managers of the Apple ecosystem, CocoaPods, Carthage and Swift PM, have not been studied. We analysed the dependencies for all publicly available open source libraries up to December 2021 and compiled a dataset containing the dependency networks of all three package managers. The dependency networks can be used to analyse how vulnerabilities are propagated through transitive dependencies. In order to ease the tracing of vulnerable libraries we also queried the NVD database and included publicly reported vulnerabilities for these libraries in the dataset.",
        "authors": [
            {
                "name": "Kristiina Rahkema",
                "institution": "University of Tartu",
                "country": "Estonia"
            },
            {
                "name": "Dietmar Pfahl",
                "institution": "University of Tartu",
                "country": "Estonia"
            }
        ]
    },
    {
        "title": "Comments on Comments: Where Code Review and Documentation Meet",
        "topics": "Technical Papers",
        "abstract": "An important function of code review is to increase understanding; helping reviewers understand a code change aides in knowledge transfer and finding bugs. Comments in code largely serve a similar purpose, helping future readers understand the program. It is thus natural to study what happens when these two forms of understanding collide. We ask: what documentation-related comments do reviewers make and how do they affect understanding of the contribution? We analyze ca.~700K review comments on 2,000 (Java and Python) GitHub projects, and propose several filters to identify which comments are likely to be either in response to a change in documentation and/or a call for such a change. We identify 65K such cases. We next develop a taxonomy of the reviewer intents behind such \u201ccomments on comments\u201d. We find that achieving a shared understanding of the code is key: reviewer comments most often focused on clarification, followed by pointing out issues to fix, such as typos and outdated comments. Curiously, clarifying comments were frequently suggested (often verbatim) by the reviewer, indicating a desire to persist their understanding acquired during code review. We conclude with a discussion of implications of our comments-on-comments dataset for research on improving code review, including the potential benefits for automating code review.",
        "authors": [
            {
                "name": "Nikitha Rao",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            },
            {
                "name": "Jason Tsay",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Martin Hirzel",
                "institution": "IBM Research",
                "country": "United States"
            },
            {
                "name": "Vincent J. Hellendoorn",
                "institution": "Carnegie Mellon University",
                "country": "United States"
            }
        ]
    },
    {
        "title": "Refactoring Debt: Myth or Reality? An Exploratory Study on the Relationship Between Technical Debt and Refactoring",
        "topics": "Mining Challenge",
        "abstract": "To meet project timelines or budget constraints, developers intentionally deviate from writing optimal code to feasible code in what is known as incurring Technical Debt (TD). Furthermore, as part of planning their correction, developers document these deficiencies as comments in the code (i.e., self-admitted technical debt or SATD). As a means of improving source code quality, developers often apply a series of refactoring operations to their codebase. In this study, we explore developers repaying this debt through refactoring operations by examining occurrences of SATD removal in the code of 76 open-source Java systems. Our findings show that TD payment usually occurs with refactoring activities and developers refactor their code to remove TD for specific reasons. We envision our findings supporting vendors in providing tools to better support developers in the automatic repayment of technical debt.",
        "authors": [
            {
                "name": "Anthony Peruma",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Eman Abdullah AlOmar",
                "institution": "Stevens Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Christian D. Newman",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Mohamed Wiem Mkaouer",
                "institution": "Rochester Institute of Technology",
                "country": "United States"
            },
            {
                "name": "Ali Ouni",
                "institution": "ETS Montreal, University of Quebec",
                "country": "Canada"
            }
        ]
    },
    {
        "title": "SoCCMiner: A Source Code-Comments and Comment-Context Miner",
        "topics": "Data and Tool Showcase Track",
        "abstract": "Numerous tools exist for mining source code and software development process metrics. However, very few publicly available tools focus on source code comments, a crucial software artifact. This paper presents SoCCMiner (Source Code-Comments and Comment-Context Miner), a tool that offers multiple mining pipelines. It is the first readily available (plug-and-play) and customizable open-source tool for mining source code contextual information of comments at different granularities (Class comments, Method comments, Interface comments, and other granular comments). Mining comments at different source code granularities can aid researchers and practitioners working in a host of applications that focus on source code comments, such as Self-Admitted Technical Debt, Program Comprehension, and other applications. Furthermore, it is highly adaptable and extendable to include additional attributes and support other programming languages. This prototype supports the Java programming language.",
        "authors": [
            {
                "name": "Murali Sridharan",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Mika M\u00e4ntyl\u00e4",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Ma\u00eblick Claes",
                "institution": "University of Oulu",
                "country": "Finland"
            },
            {
                "name": "Leevi Rantala",
                "institution": "University of Oulu",
                "country": "Finland"
            }
        ]
    },
    {
        "title": "Investigating the Impact of Forgetting in Software Development",
        "topics": "Registered Reports",
        "abstract": "Context: Forgetting is defined as a gradual process of losing information. Even though there are many studies demonstrating the effect of forgetting in software development, to the best of our knowledge, no study explores the impact of forgetting in software development using a controlled experiment approach. Objective: We would like to provide insights on the impact of forgetting in software development projects. We want to examine whether the recency & frequency of interaction impact forgetting in software development. Methods: We will conduct an experiment that examines the impact of forgetting in software development. Participants will first do an initial task. According to their initial task performance, they will be assigned to either the experiment or the control group. The experiment group will then do two additional tasks to enhance their exposure to the code. Both groups will then do a final task to see if additional exposure to the code benefits the experiment group\u2019s performance in the final task.  Finally, we will conduct a survey and a recall task with the same participants to collect data about their perceptions of forgetting and quantify their memory performance, respectively",
        "authors": [
            {
                "name": "Utku Unal",
                "institution": "METU",
                "country": null
            },
            {
                "name": "Eray T\u00fcz\u00fcn",
                "institution": "Bilkent University",
                "country": "Turkey"
            },
            {
                "name": "Tamer Gezici",
                "institution": "Bilkent University",
                "country": null
            },
            {
                "name": "Ausaf Ahmed Farooqui",
                "institution": "Bilkent University",
                "country": null
            }
        ]
    },
    {
        "title": "Painting the Landscape of Automotive Software in GitHub",
        "topics": "Technical Papers",
        "abstract": "The automotive industry has transitioned from being electro-mechanical to a software-intensive industry. A current high-end production vehicle contains 100 million+ lines of code surpassing  modern airplanes, the Large Hadron Collider, the Android OS, and Facebook\u2019s front-end software, in code size by a huge margin. Today, software companies worldwide, including Apple, Google, Huawei, Baidu, and Sony are reportedly working to bring their vehicles to the road. This paper ventures into the automotive software landscape in open source, providing a first glimpse into this multi-disciplinary industry with a long history of closed source development. We  paint the landscape of automotive software on GitHub by describing their characteristics and development styles.",
        "authors": [
            {
                "name": "Sangeeth Kochanthara",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Yanja Dajsuren",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Loek Cleophas",
                "institution": "Eindhoven University of Technology (TU/e) and Stellenbosch University (SU)",
                "country": "Netherlands"
            },
            {
                "name": "Mark van den Brand",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            }
        ]
    },
    {
        "title": "A Large-scale Dataset of (Open Source) License Text Variants",
        "topics": "Data and Tool Showcase Track",
        "abstract": "We introduce a large-scale dataset of the complete texts of free/open source software (FOSS) license variants. To assemble it we have collected from the Software Heritage archive\u2014the largest publicly available archive of FOSS source code with accompanying development history\u2014all versions of files whose names are commonly used to convey licensing terms to software users and developers. The dataset consists of 6.5 million unique license files that can be used to conduct empirical studies on open source licensing, training of automated license classifiers, natural language processing (NLP) analyses of legal texts, as well as historical and phylogenetic studies on FOSS licensing. Additional metadata about shipped license files are also provided, making the dataset ready to use in various contexts; they include: file length measures, detected MIME type, detected SPDX license (using ScanCode), example origin (e.g., GitHub repository), oldest public commit in which the license appeared. The dataset is released as open data as an archive file containing all deduplicated license blobs, plus several portable CSV files for metadata, referencing blobs via cryptographic checksums.",
        "authors": [
            {
                "name": "Stefano Zacchiroli",
                "institution": "T\u00e9l\u00e9com Paris, Polytechnic Institute of Paris",
                "country": "France"
            }
        ]
    },
    {
        "title": "Operationalizing Threats to MSR Studies by Simulation-Based Testing",
        "topics": "Technical Papers",
        "abstract": "Quantitative studies on the border between Mining Software Repository (MSR) and Empirical Software Engineering (ESE) apply data analysis methods, like regression modeling, statistic tests or correlation analysis, to commits or pulls to better understand the software development process. Such studies assure the validity of the reported results by following a sound methodology. However, with increasing complexity, parts of the methodology can still go wrong. This may result in MSR/ESE studies with undetected threats to validity. In this paper, we propose to systematically protect against threats by operationalizing their treatment using simulations. A simulation substitutes observed and unobserved data, related to an MSR/ESE scenario, with synthetic data, carefully defined according to plausible assumptions on the scenario. Within a simulation, unobserved data becomes transparent, which is the key difference to a real study, necessary to detect threats to an analysis methodology. Running an analysis methodology on synthetic data may detect basic technical bugs and misinterpretations, but it also improves the trust in the methodology. The contribution of a simulation is to operationalize testing the impact of important assumptions. Assumptions still need to be rated for plausibility. We evaluate simulation-based testing by operationalizing undetected threats in the context of four published MSR/ESE studies. We recommend that future research uses such more systematic treatment of threats, as a contribution against the reproducibility crisis.",
        "authors": [
            {
                "name": "Johannes H\u00e4rtel",
                "institution": "University of Koblenz-Landau",
                "country": "Germany"
            },
            {
                "name": "Ralf Laemmel",
                "institution": "Facebook London",
                "country": null
            }
        ]
    },
    {
        "title": "Between JIRA and GitHub: ASFBot and its Influence on Human Comments in Issue Trackers",
        "topics": "Mining Challenge",
        "abstract": "In recent years many Open-Source Software (OSS) projects have adopted various automations to automate repetitive tasks, one category of automations adopted by OSS are so-called bots. In previous work, researchers have found that the adoption of bots helps open-source developers merge more pull requests and reduces the need for communication between developers. The Apache Software Foundation (ASF) is a foundation that provides open-source software, and it supports the OSS projects that are a member of it. Projects that are a part of the ASF can choose to adopt the ASFBot, this bot automatically creates links between the JIRA issue tracker and pull requests (PRs) on GitHub. In this exploratory case study, we zoom in on the ASF ecosystem, and we seek to understand how the adoption of one specific bot (the ASFBot) impacts the discussions in the issue-trackers of these projects. In this study, we use the SmartShark dataset to investigate whether the ASFBot affects (i)human comments mentioning pull requests (PRs) and fixes in issue comments and (ii) the general human comment rate on issues. We apply a regression discontinuity design (RDD) on nine projects that are members of the ASF and which have been active both before and after the adoption of the ASFBot. Our results indicate (i) a decrease in comments mentioning pull requests and fixes after the bot adoption and (ii) no effect in the number of human comments after the bot adoption. By taking a first step towards understanding how the adoption of ASFBot impacts the issue tracker of projects we can better understand the advantages that the infrastructure of a foundation like ASF provides, and how it affects the commenting behavior of developers in the issue-tracker.",
        "authors": [
            {
                "name": "Ambarish Moharil",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Dmitrii Orlov",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Samar Jameel",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Tristan Trouwen",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Nathan Cassee",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            },
            {
                "name": "Alexander Serebrenik",
                "institution": "Eindhoven University of Technology",
                "country": "Netherlands"
            }
        ]
    }
]